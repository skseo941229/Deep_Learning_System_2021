{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4-sukyungseo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNVlVdbCE0Ae"
      },
      "source": [
        "#1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cj0eG2iOeEG"
      },
      "source": [
        "1-1-a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fghCl_AUEEgX"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.datasets import cifar10\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_JrAcNREpFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbec5ef4-0308-4d62-bee9-d62236b5d22b"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar100.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 12s 0us/step\n",
            "169017344/169001437 [==============================] - 12s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEDa222qQAhw"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train  /= 255.0\n",
        "x_test /= 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTWubeYpFS7v"
      },
      "source": [
        "y_train=np_utils.to_categorical(y_train)\n",
        "y_test=np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG9U2NnxIsgA"
      },
      "source": [
        "Number of class : 100  \n",
        "Number of images per class : 600  \n",
        "There are 20 targetsuperclasses.  \n",
        "50000 training and 10000 test dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "g5IJ2cggJc9b",
        "outputId": "c05e280f-ebe4-4ff7-deb3-282dcb1eae02"
      },
      "source": [
        "plt.imshow(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f54e07e2f90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "Nv3DYlXhJnz-",
        "outputId": "37993a55-acda-45fa-94b7-7e32a639d6fa"
      },
      "source": [
        "plt.imshow(x_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6d6f2e4a10>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "TniZajRhJpse",
        "outputId": "10e1c8c1-da76-4645-d315-52064d5549a1"
      },
      "source": [
        "plt.imshow(x_train[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6d6f25f450>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbRklEQVR4nO2dXYxdZ3WG37X3+RnbM45/xnaMnTghpCALQRKN0tBEiAZRpQg1IFURXKBcRBhVRCoSvYhSqaRSL6AqIC4qKtNEhIoSUn6K26YtaYQUIUrAoYkTkrYkqRPsOLbHfzOeOf979eIco0m03zXjMzNnTL73kSyf2et8+1vn23vNnvneWWuZu0MI8eYnW2sHhBCjQcEuRCIo2IVIBAW7EImgYBciERTsQiRCZTmDzew2AF8GkAP4W3f/XPT+yclJ37NnD7FGEuAQ8uAloygO50g4apRyqVngx+imAiLjxTsSjQjdiKxD+79yvPzyK5ieni6dbOhgN7McwF8D+ACAIwB+ZmYH3P05NmbPnj34yU9+XGorvEPncu+W+xBcscgW4dFtQExx7F38+frn7HFbj68Vw6JIsuAHvIzfIkXBP0DhRfnpgrnynNsi/4f5W5HoOlsQmFkW+BjYwjW2nNsIzPv33HQzHbOcH+NvBPCCu7/k7m0ADwG4fRnnE0KsIssJ9l0AfrXg6yODY0KIS5BV36Azs31mdtDMDk5Pn1zt6YQQhOUE+1EAVyz4evfg2Otw9/3uPuXuU5OT25YxnRBiOSwn2H8G4Fozu9rMagA+CuDAyrglhFhpht6Nd/eumd0N4N/Rl94ecPdfLDIKMLLLHOzGg+3GB7vBw+7GhwJPUe5HQY4D8U5xuItc8N34XrfNx5FzRrvZWR7cBoGt2w187JXvxlcrVe5HYPPguVQU5XMBfI2jtY+Ei0qV+1it1vjAnO+4O7tZV1j2XJbO7u6PAHhkOecQQowG/QWdEImgYBciERTsQiSCgl2IRFCwC5EIy9qNHwYjmkEWylAsA4VLLkMTSmXlEpv3uBQ2jCzUPyeX84pOIL2x9Q2SNNjn6hNIRoH0mZPkjjxQk6J7wMFlPgvuA2cSZiBtehYk3RTcVgRrFUpldB2jZ/HFP6f1ZBciERTsQiSCgl2IRFCwC5EICnYhEmHku/FsVzLzqOzQMNMMW/st2o0v3/Utgp3daDe+6AWJJJ0gMShIhGHeRwk+WYXvIht44kee88SPPCsflweJNVE5KA/WMbxBaGLQkDUPg3EeJK5En40pVCFBvDD0ZBciERTsQiSCgl2IRFCwC5EICnYhEkHBLkQijFx6o8kfw9Rqi5qcDNlBJJJ4ekQq60Xy2pC2SALMos9Gzhn52AsSSfIgcyWS3hiRYBQ2rYlq6EVdWtiw6B4Y0o+4p9QQDacCH+m9E4zRk12IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJsCzpzcwOA5gF0APQdfepYc8VtkJCucwQ1UAbIimoPy7ST8h81gvkjqjNUJTlRWq4AUARZmWRw/mwUlOUpcafFawGXRaLb4GNZwi2gpp8mZX7WK3yz5VFMlkg80XaYUH8AIL7IJJYmSlqXcVNS+Z33X16Bc4jhFhF9GO8EImw3GB3AD8wsyfNbN9KOCSEWB2W+2P8Le5+1My2A3jUzP7b3R9f+IbBN4F9AHDllVcsczohxLAs68nu7kcH/58A8D0AN5a8Z7+7T7n71OTk5HKmE0Isg6GD3cw2mNnEhdcAfg/AsyvlmBBiZVnOj/E7AHxvkAVUAfD37v5vi46imkFQUNBYhk8wTaROhYUBg3HknIGqFZ4xal7VjT5bxmW5LC///l2pBsUhq0HByQof1+u0qG1u/kz5+YIim+jxtZqdm6G2V0+cpLYtk7tKj+/axX+lzPNgPYYobtm3BaZhZOLs4otUDh3s7v4SgHcPO14IMVokvQmRCAp2IRJBwS5EIijYhUgEBbsQiTD6Xm9DwDLihuvmBhRBtlzUf60oWP+1oC/bMIU0EWepVce4HFar1UuPVyrBpQ6yvJrFeWqbbx6ntpNnXig93pg9RcdkLe7H3Pl5bmtyEXNiY7mu1elM0DHdLl/frMV730XhFK1/ZV35NcuqY3RMF1weZOjJLkQiKNiFSAQFuxCJoGAXIhEU7EIkwiWzGx+2QiI75GHZugDv8bmaDb77PDdTvpNsBa+Btm79Omqr1viub7VevkMLADbGd2LzGrukfBe5F2RiFN7k44JkjPne2dLjr5w4xMfMlI8BgF6XX7PLNpUnuwBAK9tZPld7Gx2zYYzbsuD52Jrj985scF9llfJzjm/eQcdUJ4iPav8khFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJcMlIb1HbJXfS/okcBwAEUg3aDT7s7DFqO3fs5dLjveBb5vbdu6mtPraJD+zw5JpOlKyzrlwGzOo8qSLLN1BbLec+5hmX8y7fXl6fbnqa14s7fobXmWu1+Gde50GLKlKvr1bjF622nkubzuohAih8ltrajaPU1jpVLsudPnGYjpncfX3p8V5w3+jJLkQiKNiFSAQFuxCJoGAXIhEU7EIkgoJdiERYVHozswcAfAjACXd/5+DYFgDfAnAVgMMA7nD38n4/b4AKbGGtNia9BbXfCi7VdFs8A6kxy6Wh5lx51ltl/Xo6Jo/a9ASfuTU/R21FNaihR7IHrckvda8X1DrrBrXOuty0HpeXHr/hyj+gY96+/RZqa8zxGnQF70KFCVZrrsUltPlaIJP1+HVpzvF7p9XgtffaRFZszXNps3amPCOu1+MZmEt5sn8NwG1vOHYPgMfc/VoAjw2+FkJcwiwa7IN+66ffcPh2AA8OXj8I4MMr7JcQYoUZ9nf2He5+4U/NXkO/o6sQ4hJm2Rt03i9+Tn+JNLN9ZnbQzA5On5xe7nRCiCEZNtiPm9lOABj8f4K90d33u/uUu09NbpsccjohxHIZNtgPALhz8PpOAN9fGXeEEKvFUqS3bwJ4H4BJMzsC4LMAPgfgYTO7C8DLAO5Y8oxEbuoFRSALIqPF0hu3NZo8O+nMOf6rxrmZctt4ZSsd0w0y1NpB26LI5h2ueTXPlUtDzfO8cOT5U9zWPMUz0ToNLoflRblsVLNxOiaUIoO5Zk+fo7YOyXAc28YlxfGreSHQsW1B+6eMX+vWXLDG8+Redb5Wm535z4uHLhrs7v4xYnr/YmOFEJcO+gs6IRJBwS5EIijYhUgEBbsQiaBgFyIRRltw0h1wIk+w4wCMZL1xkQHwQMbptrkM0mryjLhut3xcJQ/6awVFMZvn+VytGS4dthu8YGZztlwqmzvL5ca56eAzT/P+a43z3NYlmVy9Nr9qrQbP2GoG0lunya8nk23zMf6cW/8cz2LcdCUvwDm2mRfu7AV3a49lKmZ8zOT28vuj6KnXmxDJo2AXIhEU7EIkgoJdiERQsAuRCAp2IRJhxL3enBaC9F5QvZCNKYLCi50oo4xXKGzOB5lc5PhYzrOkvBHMdTaQ0Ka5bf4Ml8rmzpVLbI0ZPqY5y4sotkkWHQCcn+FyXqtVLqN1gl5k7RZfq1aby3JFkFmYZeXPs0o3KsDJ753eeT5XfZyvsVX4fBm5f6rrg55+v0XWKogJPdmFSAQFuxCJoGAXIhEU7EIkgoJdiEQY8W48T1BhLZ4AoNct35UsglY3RZvv+naDGm68KDZQycp3Tb3FB82d4DXcmtNBLbkTXBWYO8N3wefJrns7aJ/UCBJyzjf4bvx8oFy0ye55L9g5j3bqu12+VlHSU2blz7PCeZKJGa9PZ84Vgx6rJQcgz/k580q93LCZP4uNteUK7l892YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EIS2n/9ACADwE44e7vHBy7D8AnAJwcvO1ed39kaVNevPTGbFG9rR5JngGAPOeyS7XC2/u0W+W1zhpnAwmqE9TCO8XlpPZ00C7odFC7bo60f5rniTVzc4H01gtqv3UvXiorSL01IJblousZQ651kOzSaQf3TiBtgSvByPMgEaZe/sy1brBWRMpz4/f2Up7sXwNwW8nxL7n7dYN/Swx0IcRasWiwu/vjAE6PwBchxCqynN/Z7zazQ2b2gJltXjGPhBCrwrDB/hUA1wC4DsAxAF9gbzSzfWZ20MwOnpw+NeR0QojlMlSwu/txd+95f+fsqwBuDN67392n3H1q2yTvYy6EWF2GCnYz27ngy48AeHZl3BFCrBZLkd6+CeB9ACbN7AiAzwJ4n5ldh76OdhjAJ5cymcNROJNkgkw0EAmCZDT1zxfJOEEdtKDW2dxMuQzVDSSjaovLWpgJ6uSdiWrXBTXoiPQ21+TSW6PDP3Pb+VqxtkVAlN3ItasgES2UlCI1DFZuNQT13YLTtSPpMMiWy8l9DwAV4kql4NclIxpg1BJt0WB394+VHL5/sXFCiEsL/QWdEImgYBciERTsQiSCgl2IRFCwC5EIoy046Vx6iaQy1t6n1+OyUBFJRkHGU+FcPpmdL89EOzNzjo4Z74xR21iDZ9j15rjsErWoajTKbQ2SsQcAzWAdO4EQVQQymhGpzAOhLJLQQnltiHGRBDhshl3kYyRT9rx8vlqQVZjl5DkdaG96sguRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIRRt7rDYHkwYeQgpOBvNZp8yyvdivIJsq4HOZZ+XIdP3WMjjlxms91ebaJ2ipcXcP8HM+IazTLB3Z6POuqG9gi6S26kkx6i4jkqSIoSBphRIsK3SuCDLss8HFIyS4n80XFOY0VRl1mwUkhxJsABbsQiaBgFyIRFOxCJIKCXYhEGPFuvKNg9d+CZIysS+ptdfju55npaWp75fCL1JYH9ekystN5era87hsAnD7Gy2fP5Xzcpjb/Pmw9vuPa7Jbv/jeCHfd2sNPdDauaRbBdcH6+ItjejxJXLt4LIKo056RuXd/G5/Is2AmvBC3HslrpcRsrPw4AlXq9fIx244UQCnYhEkHBLkQiKNiFSAQFuxCJoGAXIhGW0v7pCgBfB7AD/dyH/e7+ZTPbAuBbAK5CvwXUHe5+JjqXu6NgElvQQqnXLB9z5OVX6Jgn/vNxajv+6mFqe+uendRWz8vljqzKk2eqOyapLRvnna4bp2eprX2Ey3ntdnmSTKcTJLsECRedQMqJZB5msyyQFMHr/w2pvNG8kNyChJYskN4CeS1qUZVV+Gerbyq/ry676i10zPrNG8vnyfk8S3mydwF8xt33ArgJwKfMbC+AewA85u7XAnhs8LUQ4hJl0WB392Pu/vPB61kAzwPYBeB2AA8O3vYggA+vlpNCiOVzUb+zm9lVAK4H8ASAHe5+IZH7NfR/zBdCXKIsOdjNbBzAdwB82t1nFtq8/7eMpb/omNk+MztoZgdPnTq9LGeFEMOzpGA3syr6gf4Nd//u4PBxM9s5sO8EcKJsrLvvd/cpd5/aunXLSvgshBiCRYPd+tuq9wN43t2/uMB0AMCdg9d3Avj+yrsnhFgplpL1djOAjwN4xsyeGhy7F8DnADxsZncBeBnAHYudyN3RJRLb7CyXmp788U9Kjz/xIy6vvXb0/6htYh2XJ96yZYLaahPl0sqmyzbQMeOTvM7cjl17qK0TrMevsqep7fQrr5IT8mw+i2RPcFsWyWhMhgoy9sz4dTEbYi6AFsorgsecRc/AwI+sysOpTqQyAHjLu95eenzvrb9Dx6zbUS7bRj4sGuzu/iPwTMH3LzZeCHFpoL+gEyIRFOxCJIKCXYhEULALkQgKdiESYaQFJ4uiwPzs+VLbgX/8JzruB//yr6XHvc3lqd2X8z/gaXd4a6hXXztObSBFA8c2lGctAUBeWcdtQUej8lXq0946Tm2NmbHS413nWW95i2d55T3uZBZky1WIgJNFJSCjzLagKOYwEmA8FzdmFT7Xhs1cgt2z923Utve3p0qPT+7ZTcc4y6ILVEg92YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EIo+315gW6pCDiqZO8N1uHZGVNbFhPx7QD+WS+yWUonOGyXBPlxTfqpO8WAGybLJfCAGCsO0NtnQaXFYsu97+yoVzqq49xP7rN8v5wANCen+d+NPi4SrdcKst5Eh2COo8hFhSPZAUY8xq/9Wvj/HpumORZkVt2baO2iZ2XUVuXFGGdO83rt46Nby83RLIhtQgh3lQo2IVIBAW7EImgYBciERTsQiTCSHfjzTKMjdVKbbfeejMdt25d+fekV158gY5hCTcAUKvxRBJ4uX8AcPpU+U59vc53xzduLFcfAADWpKZqzsfVc77jOk6ScjaM8ySNIkgymQ3WMVrjbpO0oWoHCTlkBx8AsiBpKM/5M6tClJL6Rq7kbAjqEI5v5vdOfSNXPJpdrq6cmT5Serw2znfwt+y8ptyg3XghhIJdiERQsAuRCAp2IRJBwS5EIijYhUiERaU3M7sCwNfRb8nsAPa7+5fN7D4AnwBwcvDWe939kfhsjoL80f/WIMHgHXuvLj2+cQNvF3Q26Bjb7fJWSBWSOAEARa9c1sgyPmZigkteeTDXujqXADdu4LaxsfJzrt/I19cCPzZt5uOaTS4dNlvl0ls7GIMOl+WyoGhctP41so5j47w24BhJJgKAdeuq1Favcz+qQZZPl9RSbMydo2OM3Ius3RWwNJ29C+Az7v5zM5sA8KSZPTqwfcnd/2oJ5xBCrDFL6fV2DMCxwetZM3sewK7VdkwIsbJc1O/sZnYVgOsBPDE4dLeZHTKzB8ysvK2kEOKSYMnBbmbjAL4D4NPuPgPgKwCuAXAd+k/+L5Bx+8zsoJkdPBUk4wshVpclBbuZVdEP9G+4+3cBwN2Pu3vP3QsAXwVwY9lYd9/v7lPuPrV1ix7+QqwViwa79Vtq3A/geXf/4oLjOxe87SMAnl1594QQK8VSduNvBvBxAM+Y2VODY/cC+JiZXYf+Zv9hAJ9c7ERFUaDVKM8ca8zN0XFjtfLMpZ1X8PY423eSGl0AKhboEz0u/7Qa5fXYWiTDC+DthwCgXg2ytQJ5rbeVy3k9IslUa1xOMuOSUb6eZ4dF9IryYnOdNq9bhyKoDRhk5nnQhorVoKsGdQMrQX26vMJtVdaSCUC1GpyTzRe0cnIw/4N7ip9ucFL3H5FpF9HUhRCXEvoLOiESQcEuRCIo2IVIBAW7EImgYBciEUZbcBJATjKUxtfzQn41Ir21guw1eCDjdLn805rnhQHPz5T7fj5INeoFUl6txr/XVmtcessyvlbu5efMcy41AVwyYtJV/5zBs4JIjk4kOSB+8gQqVCi9Mekzq/DZPEodC4jWKsv4JzAiwVbIfQ8ATq5Z5Lme7EIkgoJdiERQsAuRCAp2IRJBwS5EIijYhUiEkUpvMEOWlX9/qY/xPlljWbmtG2ZCccmr3eA9yiyQ7Aoi9XXbXAJstXlGXJZF2VX8+3C9ztcqz8oLIvZLEhCM++GVQPQKMvrokMCWBRLgxc8Uj8tsuHunCGS+UIoMRDEny1+r8WvGlj5eXyFEEijYhUgEBbsQiaBgFyIRFOxCJIKCXYhEGKn05nC0QbKegmJ9OZGNcueyVmE8uyoPJI08yDYDkVaCVmPI8yDbKej/FRY2DLKhcirnRRlqgeQV+DGc9MbHDJv1FpExHwPZtujx9XAPrlmQ9WaR1MektzovEkpVymCh9GQXIhEU7EIkgoJdiERQsAuRCAp2IRJh0d14MxsD8DiA+uD933b3z5rZ1QAeArAVwJMAPu7uQW8fwLIclfUTpbYs2CHPeuVuWsF3453t+gPI6jzRwSrl7akAAHl526WsxtsxdTt8SbJgGz+v8vWoBIoBq/HX6/H1iLZwIx+DjWlOMGbY3fhoh59txhfBbny4VsGHtuADUFUAAFiLqrHL+Fw06WY4teMCLQC3uvu70W/PfJuZ3QTg8wC+5O5vA3AGwF1LOJcQYo1YNNi9z4Wc0OrgnwO4FcC3B8cfBPDhVfFQCLEiLLU/ez7o4HoCwKMAXgRw1v3Xyd9HAOxaHReFECvBkoLd3Xvufh2A3QBuBPCOpU5gZvvM7KCZHTx96syQbgohlstF7ca7+1kAPwTwHgCbzH5d4mQ3gKNkzH53n3L3qS1bNy/LWSHE8Cwa7Ga2zcw2DV6vA/ABAM+jH/R/OHjbnQC+v1pOCiGWz1ISYXYCeNDMcvS/OTzs7v9sZs8BeMjM/gLAfwG4f7ETZVkFY+u3l9oskEKsKJcTiqG0H4TyybqNXHYZ31Jea47VpgOAohckQEQ6VCTVBK2EqB9B7bRQDwumipJCuC24zkH9Pwt8jJaK+eHOr7MH92JYSy6S5ULxsDwMK/VymRoA2OWMImLRYHf3QwCuLzn+Evq/vwshfgPQX9AJkQgKdiESQcEuRCIo2IVIBAW7EIlgkVyw4pOZnQTw8uDLSQDTI5ucIz9ej/x4Pb9pfuxx921lhpEG++smNjvo7lNrMrn8kB8J+qEf44VIBAW7EImwlsG+fw3nXoj8eD3y4/W8afxYs9/ZhRCjRT/GC5EIaxLsZnabmf2Pmb1gZveshQ8DPw6b2TNm9pSZHRzhvA+Y2Qkze3bBsS1m9qiZ/XLw/6on/xM/7jOzo4M1ecrMPjgCP64wsx+a2XNm9gsz++PB8ZGuSeDHSNfEzMbM7Kdm9vTAjz8fHL/azJ4YxM23zCzoVVaCu4/0H/pdql4E8FYANQBPA9g7aj8GvhwGMLkG874XwA0Anl1w7C8B3DN4fQ+Az6+RH/cB+JMRr8dOADcMXk8A+F8Ae0e9JoEfI10T9BOLxwevqwCeAHATgIcBfHRw/G8A/NHFnHctnuw3AnjB3V/yfunphwDcvgZ+rBnu/jiA0284fDv6hTuBERXwJH6MHHc/5u4/H7yeRb84yi6MeE0CP0aK91nxIq9rEey7APxqwddrWazSAfzAzJ40s31r5MMFdrj7scHr1wDsWENf7jazQ4Mf80daS8zMrkK/fsITWMM1eYMfwIjXZDWKvKa+QXeLu98A4PcBfMrM3rvWDgH97+yIi46sJl8BcA36PQKOAfjCqCY2s3EA3wHwaXefWWgb5ZqU+DHyNfFlFHllrEWwHwVwxYKvabHK1cbdjw7+PwHge1jbyjvHzWwnAAz+P7EWTrj78cGNVgD4Kka0JmZWRT/AvuHu3x0cHvmalPmxVmsymPuii7wy1iLYfwbg2sHOYg3ARwEcGLUTZrbBzCYuvAbwewCejUetKgfQL9wJrGEBzwvBNeAjGMGamJmhX8PweXf/4gLTSNeE+THqNVm1Iq+j2mF8w27jB9Hf6XwRwJ+ukQ9vRV8JeBrAL0bpB4Bvov/jYAf9373uQr9n3mMAfgngPwBsWSM//g7AMwAOoR9sO0fgxy3o/4h+CMBTg38fHPWaBH6MdE0AvAv9Iq6H0P/G8mcL7tmfAngBwD8AqF/MefUXdEIkQuobdEIkg4JdiERQsAuRCAp2IRJBwS5EIijYhUgEBbsQiaBgFyIR/h8E5BM/UqgkJQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "K47b4Q6cJred",
        "outputId": "bb5e5fcc-4673-4f0b-c9e5-b499a1483e8e"
      },
      "source": [
        "plt.imshow(x_train[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6d6f1cc7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gevq1WKiKY0u",
        "outputId": "dbc41910-3ce7-43e1-fc47-053a74d540b5"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4P4u7dXKd5n"
      },
      "source": [
        "input_t = keras.Input(shape=(32,32,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2khTcrf4K4Nw",
        "outputId": "801ea57b-00f2-4b58-c694-4f2db9c557ab"
      },
      "source": [
        "!pip install Keras-Applications"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Keras-Applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications) (1.5.2)\n",
            "Installing collected packages: Keras-Applications\n",
            "Successfully installed Keras-Applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "Gy8edG_iJ3-r",
        "outputId": "2441fab4-b32d-4906-831d-7108f0349c5d"
      },
      "source": [
        "!pip install keras==2.2.4\n",
        "import keras\n",
        "!pip install --upgrade keras keras-applications"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.4) (1.5.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting keras\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed keras-2.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCaoEUyXLj8f"
      },
      "source": [
        "resnet_model = tf.keras.applications.ResNet50(weights=None, classes=100, input_shape=(32, 32, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XveHvDASOdFm"
      },
      "source": [
        "1-1-b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t70zJUvOiFH",
        "outputId": "bef54852-a96d-4534-82d3-552c654e6312"
      },
      "source": [
        "tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, name=\"SGD\")\n",
        "resnet_model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "resnet_history = resnet_model.fit(x_train, y_train, batch_size=64, epochs=200, validation_data=(x_test,y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "782/782 [==============================] - 3284s 4s/step - loss: 4.5745 - accuracy: 0.0820 - val_loss: 7.1056 - val_accuracy: 0.1129\n",
            "Epoch 2/200\n",
            "782/782 [==============================] - 3315s 4s/step - loss: 3.9315 - accuracy: 0.1495 - val_loss: 4.6440 - val_accuracy: 0.1239\n",
            "Epoch 3/200\n",
            "782/782 [==============================] - 3171s 4s/step - loss: 3.6644 - accuracy: 0.1909 - val_loss: 4.6722 - val_accuracy: 0.1707\n",
            "Epoch 4/200\n",
            "782/782 [==============================] - 3199s 4s/step - loss: 3.4449 - accuracy: 0.2238 - val_loss: 8.2586 - val_accuracy: 0.1940\n",
            "Epoch 5/200\n",
            "782/782 [==============================] - 3164s 4s/step - loss: 3.2254 - accuracy: 0.2577 - val_loss: 5.8243 - val_accuracy: 0.1691\n",
            "Epoch 6/200\n",
            "782/782 [==============================] - 3245s 4s/step - loss: 3.0265 - accuracy: 0.2932 - val_loss: 3.5556 - val_accuracy: 0.1860\n",
            "Epoch 7/200\n",
            "782/782 [==============================] - 3150s 4s/step - loss: 2.8232 - accuracy: 0.3235 - val_loss: 6.2220 - val_accuracy: 0.2175\n",
            "Epoch 8/200\n",
            "782/782 [==============================] - 3174s 4s/step - loss: 2.6301 - accuracy: 0.3595 - val_loss: 4.7298 - val_accuracy: 0.2424\n",
            "Epoch 9/200\n",
            "782/782 [==============================] - 3199s 4s/step - loss: 2.4361 - accuracy: 0.3942 - val_loss: 5.4268 - val_accuracy: 0.2255\n",
            "Epoch 10/200\n",
            "782/782 [==============================] - 3178s 4s/step - loss: 2.2515 - accuracy: 0.4266 - val_loss: 5.3798 - val_accuracy: 0.2264\n",
            "Epoch 11/200\n",
            "782/782 [==============================] - 3141s 4s/step - loss: 2.0547 - accuracy: 0.4641 - val_loss: 5.4915 - val_accuracy: 0.2497\n",
            "Epoch 12/200\n",
            "782/782 [==============================] - 3118s 4s/step - loss: 1.8589 - accuracy: 0.5036 - val_loss: 4.9830 - val_accuracy: 0.2504\n",
            "Epoch 13/200\n",
            "782/782 [==============================] - 3114s 4s/step - loss: 1.6811 - accuracy: 0.5429 - val_loss: 3.8576 - val_accuracy: 0.2472\n",
            "Epoch 14/200\n",
            "782/782 [==============================] - 3111s 4s/step - loss: 1.5188 - accuracy: 0.5787 - val_loss: 4.3570 - val_accuracy: 0.2434\n",
            "Epoch 15/200\n",
            "782/782 [==============================] - 3137s 4s/step - loss: 1.3392 - accuracy: 0.6230 - val_loss: 4.7021 - val_accuracy: 0.2424\n",
            "Epoch 16/200\n",
            "782/782 [==============================] - 3119s 4s/step - loss: 1.2000 - accuracy: 0.6559 - val_loss: 5.5737 - val_accuracy: 0.2463\n",
            "Epoch 17/200\n",
            "782/782 [==============================] - 3121s 4s/step - loss: 1.0615 - accuracy: 0.6923 - val_loss: 6.4354 - val_accuracy: 0.2341\n",
            "Epoch 18/200\n",
            "782/782 [==============================] - 3140s 4s/step - loss: 0.9210 - accuracy: 0.7313 - val_loss: 5.2347 - val_accuracy: 0.2168\n",
            "Epoch 19/200\n",
            "782/782 [==============================] - 3128s 4s/step - loss: 0.8102 - accuracy: 0.7601 - val_loss: 5.2946 - val_accuracy: 0.2467\n",
            "Epoch 20/200\n",
            "782/782 [==============================] - 3168s 4s/step - loss: 0.6991 - accuracy: 0.7902 - val_loss: 4.7290 - val_accuracy: 0.2433\n",
            "Epoch 21/200\n",
            "782/782 [==============================] - 3136s 4s/step - loss: 0.6239 - accuracy: 0.8129 - val_loss: 4.9028 - val_accuracy: 0.2424\n",
            "Epoch 22/200\n",
            "782/782 [==============================] - 3215s 4s/step - loss: 0.5605 - accuracy: 0.8320 - val_loss: 4.8586 - val_accuracy: 0.2518\n",
            "Epoch 23/200\n",
            "782/782 [==============================] - 3154s 4s/step - loss: 0.4825 - accuracy: 0.8554 - val_loss: 5.1926 - val_accuracy: 0.2249\n",
            "Epoch 24/200\n",
            "782/782 [==============================] - 3243s 4s/step - loss: 0.4346 - accuracy: 0.8705 - val_loss: 4.9808 - val_accuracy: 0.2686\n",
            "Epoch 25/200\n",
            "782/782 [==============================] - 3214s 4s/step - loss: 0.3652 - accuracy: 0.8899 - val_loss: 4.7662 - val_accuracy: 0.2935\n",
            "Epoch 26/200\n",
            "782/782 [==============================] - 3182s 4s/step - loss: 0.3230 - accuracy: 0.9042 - val_loss: 4.9924 - val_accuracy: 0.2821\n",
            "Epoch 27/200\n",
            "782/782 [==============================] - 3181s 4s/step - loss: 0.2968 - accuracy: 0.9116 - val_loss: 5.4326 - val_accuracy: 0.2443\n",
            "Epoch 28/200\n",
            "197/782 [======>.......................] - ETA: 39:13 - loss: 0.2674 - accuracy: 0.9216"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU3KsnGn5CjK"
      },
      "source": [
        "1-1-c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF8FF-NS9aLb"
      },
      "source": [
        "#implemented in different file \n",
        "tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, name=\"SGD\")\n",
        "resnet_model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "resnet_history = resnet_model.fit(x_train, y_train, batch_size=64, epochs=200, validation_data=(x_test,y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtJ5ZA859f1Q"
      },
      "source": [
        "#implemented in different file \n",
        "tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, name=\"SGD\")\n",
        "resnet_model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "resnet_history = resnet_model.fit(x_train, y_train, batch_size=64, epochs=200, validation_data=(x_test,y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2baNVQW5IPAh"
      },
      "source": [
        "Learning rate with 0.001 gives the best accuracy. At 0.01 gives 0.8916 accuracy. 0.1 gives 0.9188 and 0.001 gives 0.9216. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPBhPHtw5FJv"
      },
      "source": [
        "1-2-a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weHO9CrE6w7U",
        "outputId": "56dab221-5a1c-46e6-a26f-f40c5f5c3f8f"
      },
      "source": [
        "for layer in resnet_model.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "### LR 1\n",
        "tf.keras.optimizers.SGD(lr=1, momentum=0.9, name=\"SGD\")\n",
        "resnet_model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "resnet_history = resnet_model.fit(x_train, y_train, batch_size=64, epochs=200, validation_data=(x_test,y_test),verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "782/782 [==============================] - 240s 304ms/step - loss: 4.6044 - accuracy: 0.0098 - val_loss: 4.6038 - val_accuracy: 0.0097\n",
            "Epoch 2/200\n",
            "782/782 [==============================] - 219s 280ms/step - loss: 4.6033 - accuracy: 0.0094 - val_loss: 4.6027 - val_accuracy: 0.0093\n",
            "Epoch 3/200\n",
            "782/782 [==============================] - 223s 286ms/step - loss: 4.6022 - accuracy: 0.0103 - val_loss: 4.6017 - val_accuracy: 0.0093\n",
            "Epoch 4/200\n",
            "782/782 [==============================] - 219s 280ms/step - loss: 4.6012 - accuracy: 0.0096 - val_loss: 4.6007 - val_accuracy: 0.0084\n",
            "Epoch 5/200\n",
            "782/782 [==============================] - 219s 281ms/step - loss: 4.6003 - accuracy: 0.0100 - val_loss: 4.5998 - val_accuracy: 0.0101\n",
            "Epoch 6/200\n",
            "782/782 [==============================] - 222s 284ms/step - loss: 4.5994 - accuracy: 0.0098 - val_loss: 4.5990 - val_accuracy: 0.0096\n",
            "Epoch 7/200\n",
            "782/782 [==============================] - 223s 285ms/step - loss: 4.5985 - accuracy: 0.0103 - val_loss: 4.5981 - val_accuracy: 0.0102\n",
            "Epoch 8/200\n",
            "782/782 [==============================] - 224s 286ms/step - loss: 4.5977 - accuracy: 0.0103 - val_loss: 4.5973 - val_accuracy: 0.0100\n",
            "Epoch 9/200\n",
            "782/782 [==============================] - 221s 282ms/step - loss: 4.5969 - accuracy: 0.0103 - val_loss: 4.5966 - val_accuracy: 0.0103\n",
            "Epoch 10/200\n",
            "782/782 [==============================] - 220s 281ms/step - loss: 4.5961 - accuracy: 0.0102 - val_loss: 4.5958 - val_accuracy: 0.0105\n",
            "Epoch 11/200\n",
            "782/782 [==============================] - 222s 283ms/step - loss: 4.5953 - accuracy: 0.0105 - val_loss: 4.5950 - val_accuracy: 0.0105\n",
            "Epoch 12/200\n",
            "782/782 [==============================] - 222s 284ms/step - loss: 4.5945 - accuracy: 0.0107 - val_loss: 4.5943 - val_accuracy: 0.0106\n",
            "Epoch 13/200\n",
            "782/782 [==============================] - 221s 282ms/step - loss: 4.5938 - accuracy: 0.0108 - val_loss: 4.5936 - val_accuracy: 0.0108\n",
            "Epoch 14/200\n",
            "782/782 [==============================] - 221s 282ms/step - loss: 4.5931 - accuracy: 0.0110 - val_loss: 4.5929 - val_accuracy: 0.0107\n",
            "Epoch 15/200\n",
            "782/782 [==============================] - 223s 285ms/step - loss: 4.5923 - accuracy: 0.0112 - val_loss: 4.5921 - val_accuracy: 0.0108\n",
            "Epoch 16/200\n",
            "782/782 [==============================] - 223s 285ms/step - loss: 4.5916 - accuracy: 0.0115 - val_loss: 4.5914 - val_accuracy: 0.0111\n",
            "Epoch 17/200\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 4.5909 - accuracy: 0.0120 - val_loss: 4.5907 - val_accuracy: 0.0115\n",
            "Epoch 18/200\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 4.5902 - accuracy: 0.0121 - val_loss: 4.5901 - val_accuracy: 0.0119\n",
            "Epoch 19/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5895 - accuracy: 0.0130 - val_loss: 4.5894 - val_accuracy: 0.0125\n",
            "Epoch 20/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5888 - accuracy: 0.0136 - val_loss: 4.5887 - val_accuracy: 0.0133\n",
            "Epoch 21/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5881 - accuracy: 0.0137 - val_loss: 4.5880 - val_accuracy: 0.0138\n",
            "Epoch 22/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5874 - accuracy: 0.0144 - val_loss: 4.5873 - val_accuracy: 0.0143\n",
            "Epoch 23/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5867 - accuracy: 0.0151 - val_loss: 4.5867 - val_accuracy: 0.0151\n",
            "Epoch 24/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5860 - accuracy: 0.0163 - val_loss: 4.5860 - val_accuracy: 0.0160\n",
            "Epoch 25/200\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 4.5854 - accuracy: 0.0163 - val_loss: 4.5854 - val_accuracy: 0.0165\n",
            "Epoch 26/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5847 - accuracy: 0.0171 - val_loss: 4.5847 - val_accuracy: 0.0171\n",
            "Epoch 27/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5840 - accuracy: 0.0174 - val_loss: 4.5841 - val_accuracy: 0.0178\n",
            "Epoch 28/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5834 - accuracy: 0.0177 - val_loss: 4.5834 - val_accuracy: 0.0186\n",
            "Epoch 29/200\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 4.5827 - accuracy: 0.0183 - val_loss: 4.5828 - val_accuracy: 0.0190\n",
            "Epoch 30/200\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 4.5821 - accuracy: 0.0189 - val_loss: 4.5822 - val_accuracy: 0.0196\n",
            "Epoch 31/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5814 - accuracy: 0.0188 - val_loss: 4.5815 - val_accuracy: 0.0199\n",
            "Epoch 32/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5808 - accuracy: 0.0195 - val_loss: 4.5809 - val_accuracy: 0.0199\n",
            "Epoch 33/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5802 - accuracy: 0.0196 - val_loss: 4.5803 - val_accuracy: 0.0199\n",
            "Epoch 34/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5795 - accuracy: 0.0206 - val_loss: 4.5797 - val_accuracy: 0.0202\n",
            "Epoch 35/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5789 - accuracy: 0.0203 - val_loss: 4.5791 - val_accuracy: 0.0203\n",
            "Epoch 36/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5783 - accuracy: 0.0207 - val_loss: 4.5785 - val_accuracy: 0.0212\n",
            "Epoch 37/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5777 - accuracy: 0.0213 - val_loss: 4.5779 - val_accuracy: 0.0211\n",
            "Epoch 38/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5771 - accuracy: 0.0214 - val_loss: 4.5773 - val_accuracy: 0.0212\n",
            "Epoch 39/200\n",
            "782/782 [==============================] - 231s 295ms/step - loss: 4.5765 - accuracy: 0.0220 - val_loss: 4.5767 - val_accuracy: 0.0220\n",
            "Epoch 40/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5759 - accuracy: 0.0221 - val_loss: 4.5761 - val_accuracy: 0.0214\n",
            "Epoch 41/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5753 - accuracy: 0.0223 - val_loss: 4.5755 - val_accuracy: 0.0214\n",
            "Epoch 42/200\n",
            "782/782 [==============================] - 229s 294ms/step - loss: 4.5747 - accuracy: 0.0225 - val_loss: 4.5749 - val_accuracy: 0.0215\n",
            "Epoch 43/200\n",
            "782/782 [==============================] - 232s 297ms/step - loss: 4.5741 - accuracy: 0.0229 - val_loss: 4.5744 - val_accuracy: 0.0220\n",
            "Epoch 44/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5735 - accuracy: 0.0232 - val_loss: 4.5738 - val_accuracy: 0.0222\n",
            "Epoch 45/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5729 - accuracy: 0.0235 - val_loss: 4.5732 - val_accuracy: 0.0218\n",
            "Epoch 46/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5723 - accuracy: 0.0240 - val_loss: 4.5727 - val_accuracy: 0.0220\n",
            "Epoch 47/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5718 - accuracy: 0.0240 - val_loss: 4.5721 - val_accuracy: 0.0221\n",
            "Epoch 48/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5712 - accuracy: 0.0239 - val_loss: 4.5715 - val_accuracy: 0.0222\n",
            "Epoch 49/200\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 4.5706 - accuracy: 0.0241 - val_loss: 4.5710 - val_accuracy: 0.0224\n",
            "Epoch 50/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5701 - accuracy: 0.0244 - val_loss: 4.5705 - val_accuracy: 0.0230\n",
            "Epoch 51/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5695 - accuracy: 0.0250 - val_loss: 4.5699 - val_accuracy: 0.0235\n",
            "Epoch 52/200\n",
            "782/782 [==============================] - 231s 296ms/step - loss: 4.5690 - accuracy: 0.0248 - val_loss: 4.5694 - val_accuracy: 0.0238\n",
            "Epoch 53/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5684 - accuracy: 0.0255 - val_loss: 4.5688 - val_accuracy: 0.0235\n",
            "Epoch 54/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5679 - accuracy: 0.0259 - val_loss: 4.5683 - val_accuracy: 0.0234\n",
            "Epoch 55/200\n",
            "782/782 [==============================] - 231s 296ms/step - loss: 4.5673 - accuracy: 0.0260 - val_loss: 4.5678 - val_accuracy: 0.0238\n",
            "Epoch 56/200\n",
            "782/782 [==============================] - 230s 295ms/step - loss: 4.5668 - accuracy: 0.0262 - val_loss: 4.5672 - val_accuracy: 0.0238\n",
            "Epoch 57/200\n",
            "782/782 [==============================] - 232s 297ms/step - loss: 4.5662 - accuracy: 0.0265 - val_loss: 4.5667 - val_accuracy: 0.0246\n",
            "Epoch 58/200\n",
            "782/782 [==============================] - 232s 297ms/step - loss: 4.5657 - accuracy: 0.0262 - val_loss: 4.5662 - val_accuracy: 0.0252\n",
            "Epoch 59/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5652 - accuracy: 0.0263 - val_loss: 4.5657 - val_accuracy: 0.0251\n",
            "Epoch 60/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5646 - accuracy: 0.0266 - val_loss: 4.5652 - val_accuracy: 0.0254\n",
            "Epoch 61/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5641 - accuracy: 0.0269 - val_loss: 4.5647 - val_accuracy: 0.0256\n",
            "Epoch 62/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5636 - accuracy: 0.0269 - val_loss: 4.5642 - val_accuracy: 0.0259\n",
            "Epoch 63/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5631 - accuracy: 0.0277 - val_loss: 4.5637 - val_accuracy: 0.0261\n",
            "Epoch 64/200\n",
            "782/782 [==============================] - 232s 297ms/step - loss: 4.5626 - accuracy: 0.0278 - val_loss: 4.5632 - val_accuracy: 0.0265\n",
            "Epoch 65/200\n",
            "782/782 [==============================] - 232s 296ms/step - loss: 4.5621 - accuracy: 0.0276 - val_loss: 4.5627 - val_accuracy: 0.0264\n",
            "Epoch 66/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5616 - accuracy: 0.0277 - val_loss: 4.5622 - val_accuracy: 0.0269\n",
            "Epoch 67/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5611 - accuracy: 0.0283 - val_loss: 4.5617 - val_accuracy: 0.0271\n",
            "Epoch 68/200\n",
            "782/782 [==============================] - 229s 292ms/step - loss: 4.5606 - accuracy: 0.0287 - val_loss: 4.5612 - val_accuracy: 0.0276\n",
            "Epoch 69/200\n",
            "782/782 [==============================] - 229s 292ms/step - loss: 4.5601 - accuracy: 0.0277 - val_loss: 4.5607 - val_accuracy: 0.0276\n",
            "Epoch 70/200\n",
            "782/782 [==============================] - 231s 296ms/step - loss: 4.5596 - accuracy: 0.0287 - val_loss: 4.5603 - val_accuracy: 0.0275\n",
            "Epoch 71/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5591 - accuracy: 0.0291 - val_loss: 4.5598 - val_accuracy: 0.0277\n",
            "Epoch 72/200\n",
            "782/782 [==============================] - 226s 290ms/step - loss: 4.5586 - accuracy: 0.0290 - val_loss: 4.5593 - val_accuracy: 0.0274\n",
            "Epoch 73/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5581 - accuracy: 0.0288 - val_loss: 4.5588 - val_accuracy: 0.0273\n",
            "Epoch 74/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5577 - accuracy: 0.0297 - val_loss: 4.5584 - val_accuracy: 0.0276\n",
            "Epoch 75/200\n",
            "782/782 [==============================] - 227s 291ms/step - loss: 4.5572 - accuracy: 0.0294 - val_loss: 4.5579 - val_accuracy: 0.0275\n",
            "Epoch 76/200\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 4.5567 - accuracy: 0.0292 - val_loss: 4.5575 - val_accuracy: 0.0274\n",
            "Epoch 77/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5562 - accuracy: 0.0297 - val_loss: 4.5570 - val_accuracy: 0.0273\n",
            "Epoch 78/200\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 4.5558 - accuracy: 0.0296 - val_loss: 4.5565 - val_accuracy: 0.0278\n",
            "Epoch 79/200\n",
            "782/782 [==============================] - 226s 289ms/step - loss: 4.5553 - accuracy: 0.0300 - val_loss: 4.5561 - val_accuracy: 0.0281\n",
            "Epoch 80/200\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 4.5548 - accuracy: 0.0309 - val_loss: 4.5557 - val_accuracy: 0.0281\n",
            "Epoch 81/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5544 - accuracy: 0.0303 - val_loss: 4.5552 - val_accuracy: 0.0278\n",
            "Epoch 82/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5539 - accuracy: 0.0301 - val_loss: 4.5548 - val_accuracy: 0.0281\n",
            "Epoch 83/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5535 - accuracy: 0.0305 - val_loss: 4.5543 - val_accuracy: 0.0285\n",
            "Epoch 84/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5530 - accuracy: 0.0304 - val_loss: 4.5539 - val_accuracy: 0.0288\n",
            "Epoch 85/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5526 - accuracy: 0.0313 - val_loss: 4.5535 - val_accuracy: 0.0290\n",
            "Epoch 86/200\n",
            "782/782 [==============================] - 224s 287ms/step - loss: 4.5521 - accuracy: 0.0313 - val_loss: 4.5530 - val_accuracy: 0.0293\n",
            "Epoch 87/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5517 - accuracy: 0.0309 - val_loss: 4.5526 - val_accuracy: 0.0293\n",
            "Epoch 88/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5513 - accuracy: 0.0313 - val_loss: 4.5522 - val_accuracy: 0.0293\n",
            "Epoch 89/200\n",
            "782/782 [==============================] - 226s 290ms/step - loss: 4.5508 - accuracy: 0.0311 - val_loss: 4.5517 - val_accuracy: 0.0290\n",
            "Epoch 90/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5504 - accuracy: 0.0315 - val_loss: 4.5513 - val_accuracy: 0.0295\n",
            "Epoch 91/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5500 - accuracy: 0.0316 - val_loss: 4.5509 - val_accuracy: 0.0302\n",
            "Epoch 92/200\n",
            "782/782 [==============================] - 227s 290ms/step - loss: 4.5495 - accuracy: 0.0321 - val_loss: 4.5505 - val_accuracy: 0.0302\n",
            "Epoch 93/200\n",
            "782/782 [==============================] - 231s 295ms/step - loss: 4.5491 - accuracy: 0.0316 - val_loss: 4.5501 - val_accuracy: 0.0306\n",
            "Epoch 94/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5487 - accuracy: 0.0323 - val_loss: 4.5497 - val_accuracy: 0.0307\n",
            "Epoch 95/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5483 - accuracy: 0.0321 - val_loss: 4.5493 - val_accuracy: 0.0310\n",
            "Epoch 96/200\n",
            "782/782 [==============================] - 229s 292ms/step - loss: 4.5479 - accuracy: 0.0326 - val_loss: 4.5489 - val_accuracy: 0.0306\n",
            "Epoch 97/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5474 - accuracy: 0.0323 - val_loss: 4.5485 - val_accuracy: 0.0311\n",
            "Epoch 98/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5470 - accuracy: 0.0324 - val_loss: 4.5481 - val_accuracy: 0.0315\n",
            "Epoch 99/200\n",
            "782/782 [==============================] - 231s 296ms/step - loss: 4.5466 - accuracy: 0.0332 - val_loss: 4.5477 - val_accuracy: 0.0315\n",
            "Epoch 100/200\n",
            "782/782 [==============================] - 232s 297ms/step - loss: 4.5462 - accuracy: 0.0327 - val_loss: 4.5473 - val_accuracy: 0.0318\n",
            "Epoch 101/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5458 - accuracy: 0.0330 - val_loss: 4.5469 - val_accuracy: 0.0328\n",
            "Epoch 102/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5454 - accuracy: 0.0327 - val_loss: 4.5465 - val_accuracy: 0.0330\n",
            "Epoch 103/200\n",
            "782/782 [==============================] - 231s 295ms/step - loss: 4.5450 - accuracy: 0.0332 - val_loss: 4.5461 - val_accuracy: 0.0328\n",
            "Epoch 104/200\n",
            "782/782 [==============================] - 231s 295ms/step - loss: 4.5446 - accuracy: 0.0326 - val_loss: 4.5457 - val_accuracy: 0.0329\n",
            "Epoch 105/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5442 - accuracy: 0.0337 - val_loss: 4.5453 - val_accuracy: 0.0326\n",
            "Epoch 106/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5438 - accuracy: 0.0338 - val_loss: 4.5449 - val_accuracy: 0.0325\n",
            "Epoch 107/200\n",
            "782/782 [==============================] - 229s 294ms/step - loss: 4.5434 - accuracy: 0.0331 - val_loss: 4.5446 - val_accuracy: 0.0327\n",
            "Epoch 108/200\n",
            "782/782 [==============================] - 231s 295ms/step - loss: 4.5430 - accuracy: 0.0327 - val_loss: 4.5442 - val_accuracy: 0.0328\n",
            "Epoch 109/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5427 - accuracy: 0.0337 - val_loss: 4.5438 - val_accuracy: 0.0333\n",
            "Epoch 110/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5423 - accuracy: 0.0337 - val_loss: 4.5434 - val_accuracy: 0.0333\n",
            "Epoch 111/200\n",
            "782/782 [==============================] - 232s 297ms/step - loss: 4.5419 - accuracy: 0.0341 - val_loss: 4.5431 - val_accuracy: 0.0334\n",
            "Epoch 112/200\n",
            "782/782 [==============================] - 236s 302ms/step - loss: 4.5415 - accuracy: 0.0338 - val_loss: 4.5427 - val_accuracy: 0.0335\n",
            "Epoch 113/200\n",
            "782/782 [==============================] - 236s 302ms/step - loss: 4.5411 - accuracy: 0.0342 - val_loss: 4.5423 - val_accuracy: 0.0335\n",
            "Epoch 114/200\n",
            "782/782 [==============================] - 239s 305ms/step - loss: 4.5408 - accuracy: 0.0345 - val_loss: 4.5420 - val_accuracy: 0.0337\n",
            "Epoch 115/200\n",
            "782/782 [==============================] - 239s 305ms/step - loss: 4.5404 - accuracy: 0.0343 - val_loss: 4.5416 - val_accuracy: 0.0340\n",
            "Epoch 116/200\n",
            "782/782 [==============================] - 239s 305ms/step - loss: 4.5400 - accuracy: 0.0347 - val_loss: 4.5412 - val_accuracy: 0.0341\n",
            "Epoch 117/200\n",
            "782/782 [==============================] - 241s 309ms/step - loss: 4.5396 - accuracy: 0.0344 - val_loss: 4.5409 - val_accuracy: 0.0346\n",
            "Epoch 118/200\n",
            "782/782 [==============================] - 238s 305ms/step - loss: 4.5393 - accuracy: 0.0347 - val_loss: 4.5405 - val_accuracy: 0.0342\n",
            "Epoch 119/200\n",
            "782/782 [==============================] - 238s 305ms/step - loss: 4.5389 - accuracy: 0.0341 - val_loss: 4.5402 - val_accuracy: 0.0341\n",
            "Epoch 120/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5385 - accuracy: 0.0345 - val_loss: 4.5398 - val_accuracy: 0.0341\n",
            "Epoch 121/200\n",
            "782/782 [==============================] - 240s 306ms/step - loss: 4.5382 - accuracy: 0.0351 - val_loss: 4.5395 - val_accuracy: 0.0339\n",
            "Epoch 122/200\n",
            "782/782 [==============================] - 236s 301ms/step - loss: 4.5378 - accuracy: 0.0351 - val_loss: 4.5391 - val_accuracy: 0.0341\n",
            "Epoch 123/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5375 - accuracy: 0.0352 - val_loss: 4.5388 - val_accuracy: 0.0344\n",
            "Epoch 124/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5371 - accuracy: 0.0344 - val_loss: 4.5384 - val_accuracy: 0.0343\n",
            "Epoch 125/200\n",
            "782/782 [==============================] - 238s 304ms/step - loss: 4.5368 - accuracy: 0.0354 - val_loss: 4.5381 - val_accuracy: 0.0343\n",
            "Epoch 126/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5364 - accuracy: 0.0349 - val_loss: 4.5378 - val_accuracy: 0.0345\n",
            "Epoch 127/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5361 - accuracy: 0.0349 - val_loss: 4.5374 - val_accuracy: 0.0344\n",
            "Epoch 128/200\n",
            "782/782 [==============================] - 239s 305ms/step - loss: 4.5357 - accuracy: 0.0349 - val_loss: 4.5371 - val_accuracy: 0.0344\n",
            "Epoch 129/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5354 - accuracy: 0.0352 - val_loss: 4.5367 - val_accuracy: 0.0347\n",
            "Epoch 130/200\n",
            "782/782 [==============================] - 236s 302ms/step - loss: 4.5350 - accuracy: 0.0355 - val_loss: 4.5364 - val_accuracy: 0.0344\n",
            "Epoch 131/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5347 - accuracy: 0.0351 - val_loss: 4.5361 - val_accuracy: 0.0347\n",
            "Epoch 132/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5343 - accuracy: 0.0360 - val_loss: 4.5358 - val_accuracy: 0.0350\n",
            "Epoch 133/200\n",
            "782/782 [==============================] - 241s 309ms/step - loss: 4.5340 - accuracy: 0.0354 - val_loss: 4.5354 - val_accuracy: 0.0351\n",
            "Epoch 134/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5337 - accuracy: 0.0359 - val_loss: 4.5351 - val_accuracy: 0.0347\n",
            "Epoch 135/200\n",
            "782/782 [==============================] - 241s 309ms/step - loss: 4.5333 - accuracy: 0.0357 - val_loss: 4.5348 - val_accuracy: 0.0349\n",
            "Epoch 136/200\n",
            "782/782 [==============================] - 242s 310ms/step - loss: 4.5330 - accuracy: 0.0360 - val_loss: 4.5345 - val_accuracy: 0.0351\n",
            "Epoch 137/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5327 - accuracy: 0.0360 - val_loss: 4.5341 - val_accuracy: 0.0349\n",
            "Epoch 138/200\n",
            "782/782 [==============================] - 238s 304ms/step - loss: 4.5323 - accuracy: 0.0360 - val_loss: 4.5338 - val_accuracy: 0.0348\n",
            "Epoch 139/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5320 - accuracy: 0.0359 - val_loss: 4.5335 - val_accuracy: 0.0349\n",
            "Epoch 140/200\n",
            "782/782 [==============================] - 240s 306ms/step - loss: 4.5317 - accuracy: 0.0358 - val_loss: 4.5332 - val_accuracy: 0.0347\n",
            "Epoch 141/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5314 - accuracy: 0.0362 - val_loss: 4.5329 - val_accuracy: 0.0355\n",
            "Epoch 142/200\n",
            "782/782 [==============================] - 239s 305ms/step - loss: 4.5310 - accuracy: 0.0359 - val_loss: 4.5326 - val_accuracy: 0.0356\n",
            "Epoch 143/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5307 - accuracy: 0.0363 - val_loss: 4.5322 - val_accuracy: 0.0358\n",
            "Epoch 144/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5304 - accuracy: 0.0367 - val_loss: 4.5319 - val_accuracy: 0.0355\n",
            "Epoch 145/200\n",
            "782/782 [==============================] - 236s 302ms/step - loss: 4.5301 - accuracy: 0.0366 - val_loss: 4.5316 - val_accuracy: 0.0355\n",
            "Epoch 146/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5298 - accuracy: 0.0366 - val_loss: 4.5313 - val_accuracy: 0.0357\n",
            "Epoch 147/200\n",
            "782/782 [==============================] - 238s 304ms/step - loss: 4.5294 - accuracy: 0.0367 - val_loss: 4.5310 - val_accuracy: 0.0355\n",
            "Epoch 148/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5291 - accuracy: 0.0367 - val_loss: 4.5307 - val_accuracy: 0.0359\n",
            "Epoch 149/200\n",
            "782/782 [==============================] - 243s 310ms/step - loss: 4.5288 - accuracy: 0.0374 - val_loss: 4.5304 - val_accuracy: 0.0357\n",
            "Epoch 150/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5285 - accuracy: 0.0368 - val_loss: 4.5301 - val_accuracy: 0.0363\n",
            "Epoch 151/200\n",
            "782/782 [==============================] - 243s 311ms/step - loss: 4.5282 - accuracy: 0.0376 - val_loss: 4.5298 - val_accuracy: 0.0359\n",
            "Epoch 152/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5279 - accuracy: 0.0374 - val_loss: 4.5295 - val_accuracy: 0.0362\n",
            "Epoch 153/200\n",
            "782/782 [==============================] - 240s 308ms/step - loss: 4.5276 - accuracy: 0.0369 - val_loss: 4.5292 - val_accuracy: 0.0362\n",
            "Epoch 154/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5273 - accuracy: 0.0374 - val_loss: 4.5289 - val_accuracy: 0.0361\n",
            "Epoch 155/200\n",
            "782/782 [==============================] - 243s 311ms/step - loss: 4.5270 - accuracy: 0.0379 - val_loss: 4.5286 - val_accuracy: 0.0365\n",
            "Epoch 156/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5267 - accuracy: 0.0378 - val_loss: 4.5283 - val_accuracy: 0.0366\n",
            "Epoch 157/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5264 - accuracy: 0.0378 - val_loss: 4.5281 - val_accuracy: 0.0369\n",
            "Epoch 158/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5261 - accuracy: 0.0381 - val_loss: 4.5278 - val_accuracy: 0.0368\n",
            "Epoch 159/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5258 - accuracy: 0.0378 - val_loss: 4.5275 - val_accuracy: 0.0368\n",
            "Epoch 160/200\n",
            "782/782 [==============================] - 236s 302ms/step - loss: 4.5255 - accuracy: 0.0374 - val_loss: 4.5272 - val_accuracy: 0.0366\n",
            "Epoch 161/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5252 - accuracy: 0.0376 - val_loss: 4.5269 - val_accuracy: 0.0368\n",
            "Epoch 162/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5249 - accuracy: 0.0384 - val_loss: 4.5266 - val_accuracy: 0.0368\n",
            "Epoch 163/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5246 - accuracy: 0.0379 - val_loss: 4.5263 - val_accuracy: 0.0371\n",
            "Epoch 164/200\n",
            "782/782 [==============================] - 241s 309ms/step - loss: 4.5243 - accuracy: 0.0380 - val_loss: 4.5261 - val_accuracy: 0.0373\n",
            "Epoch 165/200\n",
            "782/782 [==============================] - 239s 305ms/step - loss: 4.5240 - accuracy: 0.0385 - val_loss: 4.5258 - val_accuracy: 0.0374\n",
            "Epoch 166/200\n",
            "782/782 [==============================] - 240s 308ms/step - loss: 4.5237 - accuracy: 0.0378 - val_loss: 4.5255 - val_accuracy: 0.0377\n",
            "Epoch 167/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5235 - accuracy: 0.0383 - val_loss: 4.5252 - val_accuracy: 0.0375\n",
            "Epoch 168/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5232 - accuracy: 0.0382 - val_loss: 4.5250 - val_accuracy: 0.0377\n",
            "Epoch 169/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5229 - accuracy: 0.0386 - val_loss: 4.5247 - val_accuracy: 0.0380\n",
            "Epoch 170/200\n",
            "782/782 [==============================] - 238s 304ms/step - loss: 4.5226 - accuracy: 0.0385 - val_loss: 4.5244 - val_accuracy: 0.0384\n",
            "Epoch 171/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5223 - accuracy: 0.0388 - val_loss: 4.5241 - val_accuracy: 0.0385\n",
            "Epoch 172/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5221 - accuracy: 0.0385 - val_loss: 4.5239 - val_accuracy: 0.0384\n",
            "Epoch 173/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5218 - accuracy: 0.0384 - val_loss: 4.5236 - val_accuracy: 0.0385\n",
            "Epoch 174/200\n",
            "782/782 [==============================] - 238s 304ms/step - loss: 4.5215 - accuracy: 0.0389 - val_loss: 4.5233 - val_accuracy: 0.0383\n",
            "Epoch 175/200\n",
            "782/782 [==============================] - 239s 305ms/step - loss: 4.5212 - accuracy: 0.0386 - val_loss: 4.5231 - val_accuracy: 0.0378\n",
            "Epoch 176/200\n",
            "782/782 [==============================] - 236s 302ms/step - loss: 4.5210 - accuracy: 0.0393 - val_loss: 4.5228 - val_accuracy: 0.0381\n",
            "Epoch 177/200\n",
            "782/782 [==============================] - 235s 300ms/step - loss: 4.5207 - accuracy: 0.0390 - val_loss: 4.5226 - val_accuracy: 0.0381\n",
            "Epoch 178/200\n",
            "782/782 [==============================] - 237s 303ms/step - loss: 4.5204 - accuracy: 0.0388 - val_loss: 4.5223 - val_accuracy: 0.0384\n",
            "Epoch 179/200\n",
            "782/782 [==============================] - 241s 308ms/step - loss: 4.5201 - accuracy: 0.0386 - val_loss: 4.5220 - val_accuracy: 0.0381\n",
            "Epoch 180/200\n",
            "782/782 [==============================] - 240s 307ms/step - loss: 4.5199 - accuracy: 0.0385 - val_loss: 4.5218 - val_accuracy: 0.0382\n",
            "Epoch 181/200\n",
            "782/782 [==============================] - 239s 305ms/step - loss: 4.5196 - accuracy: 0.0390 - val_loss: 4.5215 - val_accuracy: 0.0384\n",
            "Epoch 182/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5193 - accuracy: 0.0389 - val_loss: 4.5212 - val_accuracy: 0.0387\n",
            "Epoch 183/200\n",
            "782/782 [==============================] - 238s 304ms/step - loss: 4.5191 - accuracy: 0.0399 - val_loss: 4.5210 - val_accuracy: 0.0386\n",
            "Epoch 184/200\n",
            "782/782 [==============================] - 239s 306ms/step - loss: 4.5188 - accuracy: 0.0399 - val_loss: 4.5207 - val_accuracy: 0.0385\n",
            "Epoch 185/200\n",
            "782/782 [==============================] - 235s 300ms/step - loss: 4.5185 - accuracy: 0.0384 - val_loss: 4.5205 - val_accuracy: 0.0391\n",
            "Epoch 186/200\n",
            "782/782 [==============================] - 238s 304ms/step - loss: 4.5183 - accuracy: 0.0392 - val_loss: 4.5202 - val_accuracy: 0.0397\n",
            "Epoch 187/200\n",
            "782/782 [==============================] - 236s 302ms/step - loss: 4.5180 - accuracy: 0.0391 - val_loss: 4.5200 - val_accuracy: 0.0399\n",
            "Epoch 188/200\n",
            "782/782 [==============================] - 234s 299ms/step - loss: 4.5178 - accuracy: 0.0399 - val_loss: 4.5197 - val_accuracy: 0.0396\n",
            "Epoch 189/200\n",
            "782/782 [==============================] - 230s 294ms/step - loss: 4.5175 - accuracy: 0.0393 - val_loss: 4.5195 - val_accuracy: 0.0399\n",
            "Epoch 190/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5172 - accuracy: 0.0398 - val_loss: 4.5192 - val_accuracy: 0.0401\n",
            "Epoch 191/200\n",
            "782/782 [==============================] - 229s 293ms/step - loss: 4.5170 - accuracy: 0.0394 - val_loss: 4.5190 - val_accuracy: 0.0400\n",
            "Epoch 192/200\n",
            "782/782 [==============================] - 229s 292ms/step - loss: 4.5167 - accuracy: 0.0400 - val_loss: 4.5187 - val_accuracy: 0.0402\n",
            "Epoch 193/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5165 - accuracy: 0.0398 - val_loss: 4.5185 - val_accuracy: 0.0408\n",
            "Epoch 194/200\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 4.5162 - accuracy: 0.0406 - val_loss: 4.5182 - val_accuracy: 0.0406\n",
            "Epoch 195/200\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 4.5160 - accuracy: 0.0400 - val_loss: 4.5180 - val_accuracy: 0.0404\n",
            "Epoch 196/200\n",
            "782/782 [==============================] - 226s 290ms/step - loss: 4.5157 - accuracy: 0.0406 - val_loss: 4.5178 - val_accuracy: 0.0405\n",
            "Epoch 197/200\n",
            "782/782 [==============================] - 228s 291ms/step - loss: 4.5155 - accuracy: 0.0398 - val_loss: 4.5175 - val_accuracy: 0.0405\n",
            "Epoch 198/200\n",
            "782/782 [==============================] - 226s 289ms/step - loss: 4.5152 - accuracy: 0.0403 - val_loss: 4.5173 - val_accuracy: 0.0404\n",
            "Epoch 199/200\n",
            "782/782 [==============================] - 226s 289ms/step - loss: 4.5150 - accuracy: 0.0398 - val_loss: 4.5170 - val_accuracy: 0.0408\n",
            "Epoch 200/200\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 4.5147 - accuracy: 0.0409 - val_loss: 4.5168 - val_accuracy: 0.0410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCcybY616nc-",
        "outputId": "e0a2c831-19c2-4bc6-e61e-ce009eb49f2f"
      },
      "source": [
        "import statistics\n",
        "print(statistics.mean(resnet_history.history['accuracy']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.02988360000308603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1x-nzuF3bWk"
      },
      "source": [
        "#implemented in different file\n",
        "for layer in resnet_model.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "### LR 0.1\n",
        "tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, name=\"SGD\")\n",
        "resnet_model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "resnet_history = resnet_model.fit(x_train, y_train, batch_size=64, epochs=200, validation_data=(x_test,y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y0zPsO_s3hEH",
        "outputId": "27c99908-01d9-4671-9fe8-d627d52ba7be"
      },
      "source": [
        "\n",
        "for layer in resnet_model.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "### LR 0.01\n",
        "tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, name=\"SGD\")\n",
        "resnet_model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "resnet_history = resnet_model.fit(x_train, y_train, batch_size=64, epochs=200, validation_data=(x_test,y_test),verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "782/782 [==============================] - 211s 266ms/step - loss: 4.6048 - accuracy: 0.0088 - val_loss: 4.6042 - val_accuracy: 0.0101\n",
            "Epoch 2/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.6036 - accuracy: 0.0092 - val_loss: 4.6031 - val_accuracy: 0.0117\n",
            "Epoch 3/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.6025 - accuracy: 0.0103 - val_loss: 4.6020 - val_accuracy: 0.0096\n",
            "Epoch 4/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.6015 - accuracy: 0.0096 - val_loss: 4.6011 - val_accuracy: 0.0094\n",
            "Epoch 5/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.6005 - accuracy: 0.0088 - val_loss: 4.6002 - val_accuracy: 0.0098\n",
            "Epoch 6/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5996 - accuracy: 0.0098 - val_loss: 4.5993 - val_accuracy: 0.0099\n",
            "Epoch 7/200\n",
            "782/782 [==============================] - 191s 245ms/step - loss: 4.5988 - accuracy: 0.0108 - val_loss: 4.5985 - val_accuracy: 0.0110\n",
            "Epoch 8/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.5979 - accuracy: 0.0103 - val_loss: 4.5977 - val_accuracy: 0.0112\n",
            "Epoch 9/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5971 - accuracy: 0.0105 - val_loss: 4.5969 - val_accuracy: 0.0116\n",
            "Epoch 10/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5963 - accuracy: 0.0111 - val_loss: 4.5961 - val_accuracy: 0.0116\n",
            "Epoch 11/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5956 - accuracy: 0.0115 - val_loss: 4.5954 - val_accuracy: 0.0115\n",
            "Epoch 12/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5948 - accuracy: 0.0112 - val_loss: 4.5946 - val_accuracy: 0.0118\n",
            "Epoch 13/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5940 - accuracy: 0.0110 - val_loss: 4.5939 - val_accuracy: 0.0126\n",
            "Epoch 14/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5933 - accuracy: 0.0121 - val_loss: 4.5932 - val_accuracy: 0.0127\n",
            "Epoch 15/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5926 - accuracy: 0.0127 - val_loss: 4.5925 - val_accuracy: 0.0130\n",
            "Epoch 16/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5919 - accuracy: 0.0129 - val_loss: 4.5918 - val_accuracy: 0.0130\n",
            "Epoch 17/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5911 - accuracy: 0.0134 - val_loss: 4.5911 - val_accuracy: 0.0131\n",
            "Epoch 18/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5904 - accuracy: 0.0129 - val_loss: 4.5904 - val_accuracy: 0.0140\n",
            "Epoch 19/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5897 - accuracy: 0.0133 - val_loss: 4.5897 - val_accuracy: 0.0132\n",
            "Epoch 20/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5890 - accuracy: 0.0137 - val_loss: 4.5890 - val_accuracy: 0.0135\n",
            "Epoch 21/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5883 - accuracy: 0.0135 - val_loss: 4.5883 - val_accuracy: 0.0141\n",
            "Epoch 22/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5876 - accuracy: 0.0150 - val_loss: 4.5877 - val_accuracy: 0.0144\n",
            "Epoch 23/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5870 - accuracy: 0.0159 - val_loss: 4.5870 - val_accuracy: 0.0143\n",
            "Epoch 24/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5863 - accuracy: 0.0148 - val_loss: 4.5863 - val_accuracy: 0.0149\n",
            "Epoch 25/200\n",
            "782/782 [==============================] - 192s 245ms/step - loss: 4.5856 - accuracy: 0.0162 - val_loss: 4.5857 - val_accuracy: 0.0145\n",
            "Epoch 26/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5849 - accuracy: 0.0161 - val_loss: 4.5850 - val_accuracy: 0.0152\n",
            "Epoch 27/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5843 - accuracy: 0.0164 - val_loss: 4.5844 - val_accuracy: 0.0157\n",
            "Epoch 28/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5836 - accuracy: 0.0169 - val_loss: 4.5837 - val_accuracy: 0.0169\n",
            "Epoch 29/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5830 - accuracy: 0.0190 - val_loss: 4.5831 - val_accuracy: 0.0166\n",
            "Epoch 30/200\n",
            "782/782 [==============================] - 187s 240ms/step - loss: 4.5823 - accuracy: 0.0184 - val_loss: 4.5825 - val_accuracy: 0.0174\n",
            "Epoch 31/200\n",
            "782/782 [==============================] - 187s 240ms/step - loss: 4.5817 - accuracy: 0.0187 - val_loss: 4.5818 - val_accuracy: 0.0175\n",
            "Epoch 32/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5810 - accuracy: 0.0207 - val_loss: 4.5812 - val_accuracy: 0.0183\n",
            "Epoch 33/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.5804 - accuracy: 0.0198 - val_loss: 4.5806 - val_accuracy: 0.0190\n",
            "Epoch 34/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5798 - accuracy: 0.0207 - val_loss: 4.5800 - val_accuracy: 0.0191\n",
            "Epoch 35/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5791 - accuracy: 0.0201 - val_loss: 4.5794 - val_accuracy: 0.0205\n",
            "Epoch 36/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5785 - accuracy: 0.0212 - val_loss: 4.5788 - val_accuracy: 0.0213\n",
            "Epoch 37/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5779 - accuracy: 0.0229 - val_loss: 4.5782 - val_accuracy: 0.0216\n",
            "Epoch 38/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5773 - accuracy: 0.0240 - val_loss: 4.5776 - val_accuracy: 0.0213\n",
            "Epoch 39/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5767 - accuracy: 0.0218 - val_loss: 4.5770 - val_accuracy: 0.0217\n",
            "Epoch 40/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5761 - accuracy: 0.0222 - val_loss: 4.5764 - val_accuracy: 0.0223\n",
            "Epoch 41/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5755 - accuracy: 0.0235 - val_loss: 4.5758 - val_accuracy: 0.0236\n",
            "Epoch 42/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5749 - accuracy: 0.0241 - val_loss: 4.5752 - val_accuracy: 0.0240\n",
            "Epoch 43/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5743 - accuracy: 0.0237 - val_loss: 4.5746 - val_accuracy: 0.0241\n",
            "Epoch 44/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5737 - accuracy: 0.0255 - val_loss: 4.5740 - val_accuracy: 0.0245\n",
            "Epoch 45/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5731 - accuracy: 0.0255 - val_loss: 4.5735 - val_accuracy: 0.0249\n",
            "Epoch 46/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5725 - accuracy: 0.0249 - val_loss: 4.5729 - val_accuracy: 0.0259\n",
            "Epoch 47/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5719 - accuracy: 0.0253 - val_loss: 4.5723 - val_accuracy: 0.0259\n",
            "Epoch 48/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5713 - accuracy: 0.0257 - val_loss: 4.5718 - val_accuracy: 0.0259\n",
            "Epoch 49/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5708 - accuracy: 0.0257 - val_loss: 4.5712 - val_accuracy: 0.0263\n",
            "Epoch 50/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5702 - accuracy: 0.0274 - val_loss: 4.5707 - val_accuracy: 0.0259\n",
            "Epoch 51/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5696 - accuracy: 0.0263 - val_loss: 4.5701 - val_accuracy: 0.0256\n",
            "Epoch 52/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5691 - accuracy: 0.0273 - val_loss: 4.5696 - val_accuracy: 0.0261\n",
            "Epoch 53/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5685 - accuracy: 0.0272 - val_loss: 4.5690 - val_accuracy: 0.0261\n",
            "Epoch 54/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5680 - accuracy: 0.0263 - val_loss: 4.5685 - val_accuracy: 0.0270\n",
            "Epoch 55/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5674 - accuracy: 0.0272 - val_loss: 4.5679 - val_accuracy: 0.0271\n",
            "Epoch 56/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5669 - accuracy: 0.0278 - val_loss: 4.5674 - val_accuracy: 0.0272\n",
            "Epoch 57/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5663 - accuracy: 0.0280 - val_loss: 4.5669 - val_accuracy: 0.0276\n",
            "Epoch 58/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5658 - accuracy: 0.0274 - val_loss: 4.5664 - val_accuracy: 0.0274\n",
            "Epoch 59/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5653 - accuracy: 0.0275 - val_loss: 4.5658 - val_accuracy: 0.0287\n",
            "Epoch 60/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5647 - accuracy: 0.0276 - val_loss: 4.5653 - val_accuracy: 0.0284\n",
            "Epoch 61/200\n",
            "782/782 [==============================] - 187s 240ms/step - loss: 4.5642 - accuracy: 0.0283 - val_loss: 4.5648 - val_accuracy: 0.0288\n",
            "Epoch 62/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5637 - accuracy: 0.0276 - val_loss: 4.5643 - val_accuracy: 0.0282\n",
            "Epoch 63/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5631 - accuracy: 0.0299 - val_loss: 4.5638 - val_accuracy: 0.0284\n",
            "Epoch 64/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5626 - accuracy: 0.0285 - val_loss: 4.5633 - val_accuracy: 0.0285\n",
            "Epoch 65/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5621 - accuracy: 0.0287 - val_loss: 4.5628 - val_accuracy: 0.0293\n",
            "Epoch 66/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5616 - accuracy: 0.0298 - val_loss: 4.5623 - val_accuracy: 0.0296\n",
            "Epoch 67/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5611 - accuracy: 0.0298 - val_loss: 4.5618 - val_accuracy: 0.0290\n",
            "Epoch 68/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5606 - accuracy: 0.0297 - val_loss: 4.5613 - val_accuracy: 0.0290\n",
            "Epoch 69/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5601 - accuracy: 0.0292 - val_loss: 4.5608 - val_accuracy: 0.0303\n",
            "Epoch 70/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5596 - accuracy: 0.0290 - val_loss: 4.5603 - val_accuracy: 0.0306\n",
            "Epoch 71/200\n",
            "782/782 [==============================] - 188s 240ms/step - loss: 4.5591 - accuracy: 0.0304 - val_loss: 4.5598 - val_accuracy: 0.0300\n",
            "Epoch 72/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5586 - accuracy: 0.0307 - val_loss: 4.5593 - val_accuracy: 0.0303\n",
            "Epoch 73/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5581 - accuracy: 0.0315 - val_loss: 4.5589 - val_accuracy: 0.0307\n",
            "Epoch 74/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5576 - accuracy: 0.0304 - val_loss: 4.5584 - val_accuracy: 0.0311\n",
            "Epoch 75/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5571 - accuracy: 0.0316 - val_loss: 4.5579 - val_accuracy: 0.0311\n",
            "Epoch 76/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5566 - accuracy: 0.0320 - val_loss: 4.5574 - val_accuracy: 0.0308\n",
            "Epoch 77/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5561 - accuracy: 0.0326 - val_loss: 4.5570 - val_accuracy: 0.0310\n",
            "Epoch 78/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5557 - accuracy: 0.0315 - val_loss: 4.5565 - val_accuracy: 0.0313\n",
            "Epoch 79/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5552 - accuracy: 0.0313 - val_loss: 4.5560 - val_accuracy: 0.0311\n",
            "Epoch 80/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5547 - accuracy: 0.0311 - val_loss: 4.5556 - val_accuracy: 0.0317\n",
            "Epoch 81/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5543 - accuracy: 0.0313 - val_loss: 4.5551 - val_accuracy: 0.0319\n",
            "Epoch 82/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5538 - accuracy: 0.0319 - val_loss: 4.5547 - val_accuracy: 0.0324\n",
            "Epoch 83/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5533 - accuracy: 0.0325 - val_loss: 4.5542 - val_accuracy: 0.0321\n",
            "Epoch 84/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5529 - accuracy: 0.0317 - val_loss: 4.5538 - val_accuracy: 0.0327\n",
            "Epoch 85/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5524 - accuracy: 0.0335 - val_loss: 4.5533 - val_accuracy: 0.0323\n",
            "Epoch 86/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5520 - accuracy: 0.0333 - val_loss: 4.5529 - val_accuracy: 0.0326\n",
            "Epoch 87/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5515 - accuracy: 0.0320 - val_loss: 4.5525 - val_accuracy: 0.0327\n",
            "Epoch 88/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5511 - accuracy: 0.0345 - val_loss: 4.5520 - val_accuracy: 0.0324\n",
            "Epoch 89/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5506 - accuracy: 0.0330 - val_loss: 4.5516 - val_accuracy: 0.0324\n",
            "Epoch 90/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5502 - accuracy: 0.0333 - val_loss: 4.5512 - val_accuracy: 0.0328\n",
            "Epoch 91/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5497 - accuracy: 0.0332 - val_loss: 4.5507 - val_accuracy: 0.0327\n",
            "Epoch 92/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5493 - accuracy: 0.0335 - val_loss: 4.5503 - val_accuracy: 0.0322\n",
            "Epoch 93/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5488 - accuracy: 0.0336 - val_loss: 4.5499 - val_accuracy: 0.0325\n",
            "Epoch 94/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5484 - accuracy: 0.0336 - val_loss: 4.5494 - val_accuracy: 0.0333\n",
            "Epoch 95/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5480 - accuracy: 0.0341 - val_loss: 4.5490 - val_accuracy: 0.0334\n",
            "Epoch 96/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5475 - accuracy: 0.0336 - val_loss: 4.5486 - val_accuracy: 0.0335\n",
            "Epoch 97/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5471 - accuracy: 0.0352 - val_loss: 4.5482 - val_accuracy: 0.0332\n",
            "Epoch 98/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5467 - accuracy: 0.0344 - val_loss: 4.5478 - val_accuracy: 0.0337\n",
            "Epoch 99/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5463 - accuracy: 0.0349 - val_loss: 4.5474 - val_accuracy: 0.0338\n",
            "Epoch 100/200\n",
            "782/782 [==============================] - 190s 242ms/step - loss: 4.5459 - accuracy: 0.0342 - val_loss: 4.5470 - val_accuracy: 0.0339\n",
            "Epoch 101/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5454 - accuracy: 0.0348 - val_loss: 4.5466 - val_accuracy: 0.0342\n",
            "Epoch 102/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5450 - accuracy: 0.0346 - val_loss: 4.5462 - val_accuracy: 0.0342\n",
            "Epoch 103/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5446 - accuracy: 0.0350 - val_loss: 4.5458 - val_accuracy: 0.0342\n",
            "Epoch 104/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5442 - accuracy: 0.0356 - val_loss: 4.5454 - val_accuracy: 0.0339\n",
            "Epoch 105/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5438 - accuracy: 0.0350 - val_loss: 4.5450 - val_accuracy: 0.0336\n",
            "Epoch 106/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5434 - accuracy: 0.0354 - val_loss: 4.5446 - val_accuracy: 0.0340\n",
            "Epoch 107/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5430 - accuracy: 0.0348 - val_loss: 4.5442 - val_accuracy: 0.0345\n",
            "Epoch 108/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5426 - accuracy: 0.0360 - val_loss: 4.5438 - val_accuracy: 0.0348\n",
            "Epoch 109/200\n",
            "782/782 [==============================] - 189s 241ms/step - loss: 4.5422 - accuracy: 0.0354 - val_loss: 4.5434 - val_accuracy: 0.0349\n",
            "Epoch 110/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5418 - accuracy: 0.0357 - val_loss: 4.5430 - val_accuracy: 0.0347\n",
            "Epoch 111/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5414 - accuracy: 0.0356 - val_loss: 4.5426 - val_accuracy: 0.0351\n",
            "Epoch 112/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5410 - accuracy: 0.0355 - val_loss: 4.5423 - val_accuracy: 0.0357\n",
            "Epoch 113/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5406 - accuracy: 0.0354 - val_loss: 4.5419 - val_accuracy: 0.0366\n",
            "Epoch 114/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5402 - accuracy: 0.0360 - val_loss: 4.5415 - val_accuracy: 0.0368\n",
            "Epoch 115/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5398 - accuracy: 0.0365 - val_loss: 4.5411 - val_accuracy: 0.0372\n",
            "Epoch 116/200\n",
            "782/782 [==============================] - 188s 241ms/step - loss: 4.5395 - accuracy: 0.0368 - val_loss: 4.5408 - val_accuracy: 0.0373\n",
            "Epoch 117/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5391 - accuracy: 0.0359 - val_loss: 4.5404 - val_accuracy: 0.0372\n",
            "Epoch 118/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5387 - accuracy: 0.0364 - val_loss: 4.5400 - val_accuracy: 0.0372\n",
            "Epoch 119/200\n",
            "782/782 [==============================] - 190s 242ms/step - loss: 4.5383 - accuracy: 0.0361 - val_loss: 4.5396 - val_accuracy: 0.0374\n",
            "Epoch 120/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5379 - accuracy: 0.0366 - val_loss: 4.5393 - val_accuracy: 0.0374\n",
            "Epoch 121/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5376 - accuracy: 0.0364 - val_loss: 4.5389 - val_accuracy: 0.0378\n",
            "Epoch 122/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5372 - accuracy: 0.0362 - val_loss: 4.5386 - val_accuracy: 0.0374\n",
            "Epoch 123/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5368 - accuracy: 0.0370 - val_loss: 4.5382 - val_accuracy: 0.0379\n",
            "Epoch 124/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5365 - accuracy: 0.0377 - val_loss: 4.5378 - val_accuracy: 0.0376\n",
            "Epoch 125/200\n",
            "782/782 [==============================] - 190s 242ms/step - loss: 4.5361 - accuracy: 0.0371 - val_loss: 4.5375 - val_accuracy: 0.0380\n",
            "Epoch 126/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5357 - accuracy: 0.0389 - val_loss: 4.5371 - val_accuracy: 0.0378\n",
            "Epoch 127/200\n",
            "782/782 [==============================] - 190s 242ms/step - loss: 4.5354 - accuracy: 0.0382 - val_loss: 4.5368 - val_accuracy: 0.0371\n",
            "Epoch 128/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5350 - accuracy: 0.0381 - val_loss: 4.5364 - val_accuracy: 0.0375\n",
            "Epoch 129/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5346 - accuracy: 0.0370 - val_loss: 4.5361 - val_accuracy: 0.0378\n",
            "Epoch 130/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5343 - accuracy: 0.0379 - val_loss: 4.5357 - val_accuracy: 0.0383\n",
            "Epoch 131/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5339 - accuracy: 0.0378 - val_loss: 4.5354 - val_accuracy: 0.0384\n",
            "Epoch 132/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5336 - accuracy: 0.0383 - val_loss: 4.5351 - val_accuracy: 0.0384\n",
            "Epoch 133/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5332 - accuracy: 0.0385 - val_loss: 4.5347 - val_accuracy: 0.0383\n",
            "Epoch 134/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5329 - accuracy: 0.0375 - val_loss: 4.5344 - val_accuracy: 0.0382\n",
            "Epoch 135/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5325 - accuracy: 0.0375 - val_loss: 4.5340 - val_accuracy: 0.0396\n",
            "Epoch 136/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5322 - accuracy: 0.0386 - val_loss: 4.5337 - val_accuracy: 0.0395\n",
            "Epoch 137/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5318 - accuracy: 0.0378 - val_loss: 4.5334 - val_accuracy: 0.0400\n",
            "Epoch 138/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5315 - accuracy: 0.0392 - val_loss: 4.5330 - val_accuracy: 0.0400\n",
            "Epoch 139/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5312 - accuracy: 0.0387 - val_loss: 4.5327 - val_accuracy: 0.0396\n",
            "Epoch 140/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5308 - accuracy: 0.0376 - val_loss: 4.5324 - val_accuracy: 0.0400\n",
            "Epoch 141/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5305 - accuracy: 0.0384 - val_loss: 4.5321 - val_accuracy: 0.0399\n",
            "Epoch 142/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5302 - accuracy: 0.0401 - val_loss: 4.5317 - val_accuracy: 0.0398\n",
            "Epoch 143/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5298 - accuracy: 0.0390 - val_loss: 4.5314 - val_accuracy: 0.0399\n",
            "Epoch 144/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5295 - accuracy: 0.0390 - val_loss: 4.5311 - val_accuracy: 0.0397\n",
            "Epoch 145/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5292 - accuracy: 0.0391 - val_loss: 4.5308 - val_accuracy: 0.0402\n",
            "Epoch 146/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5288 - accuracy: 0.0389 - val_loss: 4.5304 - val_accuracy: 0.0404\n",
            "Epoch 147/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5285 - accuracy: 0.0400 - val_loss: 4.5301 - val_accuracy: 0.0395\n",
            "Epoch 148/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5282 - accuracy: 0.0401 - val_loss: 4.5298 - val_accuracy: 0.0392\n",
            "Epoch 149/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5279 - accuracy: 0.0395 - val_loss: 4.5295 - val_accuracy: 0.0393\n",
            "Epoch 150/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5275 - accuracy: 0.0399 - val_loss: 4.5292 - val_accuracy: 0.0398\n",
            "Epoch 151/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5272 - accuracy: 0.0384 - val_loss: 4.5289 - val_accuracy: 0.0399\n",
            "Epoch 152/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5269 - accuracy: 0.0397 - val_loss: 4.5286 - val_accuracy: 0.0399\n",
            "Epoch 153/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5266 - accuracy: 0.0396 - val_loss: 4.5283 - val_accuracy: 0.0397\n",
            "Epoch 154/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5263 - accuracy: 0.0387 - val_loss: 4.5279 - val_accuracy: 0.0399\n",
            "Epoch 155/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5259 - accuracy: 0.0400 - val_loss: 4.5276 - val_accuracy: 0.0397\n",
            "Epoch 156/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5256 - accuracy: 0.0393 - val_loss: 4.5273 - val_accuracy: 0.0398\n",
            "Epoch 157/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5253 - accuracy: 0.0407 - val_loss: 4.5270 - val_accuracy: 0.0399\n",
            "Epoch 158/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5250 - accuracy: 0.0395 - val_loss: 4.5267 - val_accuracy: 0.0396\n",
            "Epoch 159/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5247 - accuracy: 0.0402 - val_loss: 4.5264 - val_accuracy: 0.0398\n",
            "Epoch 160/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5244 - accuracy: 0.0406 - val_loss: 4.5261 - val_accuracy: 0.0397\n",
            "Epoch 161/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5241 - accuracy: 0.0404 - val_loss: 4.5258 - val_accuracy: 0.0399\n",
            "Epoch 162/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5238 - accuracy: 0.0404 - val_loss: 4.5255 - val_accuracy: 0.0398\n",
            "Epoch 163/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5235 - accuracy: 0.0408 - val_loss: 4.5253 - val_accuracy: 0.0394\n",
            "Epoch 164/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5232 - accuracy: 0.0396 - val_loss: 4.5250 - val_accuracy: 0.0398\n",
            "Epoch 165/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5229 - accuracy: 0.0410 - val_loss: 4.5247 - val_accuracy: 0.0396\n",
            "Epoch 166/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5226 - accuracy: 0.0409 - val_loss: 4.5244 - val_accuracy: 0.0399\n",
            "Epoch 167/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5223 - accuracy: 0.0409 - val_loss: 4.5241 - val_accuracy: 0.0402\n",
            "Epoch 168/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5220 - accuracy: 0.0403 - val_loss: 4.5238 - val_accuracy: 0.0405\n",
            "Epoch 169/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5217 - accuracy: 0.0399 - val_loss: 4.5235 - val_accuracy: 0.0406\n",
            "Epoch 170/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5214 - accuracy: 0.0407 - val_loss: 4.5232 - val_accuracy: 0.0406\n",
            "Epoch 171/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5211 - accuracy: 0.0415 - val_loss: 4.5229 - val_accuracy: 0.0407\n",
            "Epoch 172/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5208 - accuracy: 0.0407 - val_loss: 4.5227 - val_accuracy: 0.0406\n",
            "Epoch 173/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5205 - accuracy: 0.0401 - val_loss: 4.5224 - val_accuracy: 0.0403\n",
            "Epoch 174/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5202 - accuracy: 0.0408 - val_loss: 4.5221 - val_accuracy: 0.0407\n",
            "Epoch 175/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5199 - accuracy: 0.0411 - val_loss: 4.5218 - val_accuracy: 0.0409\n",
            "Epoch 176/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5197 - accuracy: 0.0410 - val_loss: 4.5216 - val_accuracy: 0.0410\n",
            "Epoch 177/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5194 - accuracy: 0.0402 - val_loss: 4.5213 - val_accuracy: 0.0413\n",
            "Epoch 178/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5191 - accuracy: 0.0409 - val_loss: 4.5210 - val_accuracy: 0.0412\n",
            "Epoch 179/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5188 - accuracy: 0.0410 - val_loss: 4.5207 - val_accuracy: 0.0414\n",
            "Epoch 180/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5185 - accuracy: 0.0419 - val_loss: 4.5205 - val_accuracy: 0.0414\n",
            "Epoch 181/200\n",
            "782/782 [==============================] - 189s 242ms/step - loss: 4.5182 - accuracy: 0.0413 - val_loss: 4.5202 - val_accuracy: 0.0411\n",
            "Epoch 182/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5180 - accuracy: 0.0410 - val_loss: 4.5199 - val_accuracy: 0.0412\n",
            "Epoch 183/200\n",
            "782/782 [==============================] - 192s 245ms/step - loss: 4.5177 - accuracy: 0.0414 - val_loss: 4.5196 - val_accuracy: 0.0408\n",
            "Epoch 184/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.5174 - accuracy: 0.0404 - val_loss: 4.5194 - val_accuracy: 0.0410\n",
            "Epoch 185/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.5171 - accuracy: 0.0414 - val_loss: 4.5191 - val_accuracy: 0.0411\n",
            "Epoch 186/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.5169 - accuracy: 0.0420 - val_loss: 4.5189 - val_accuracy: 0.0406\n",
            "Epoch 187/200\n",
            "782/782 [==============================] - 190s 244ms/step - loss: 4.5166 - accuracy: 0.0409 - val_loss: 4.5186 - val_accuracy: 0.0412\n",
            "Epoch 188/200\n",
            "782/782 [==============================] - 190s 244ms/step - loss: 4.5163 - accuracy: 0.0415 - val_loss: 4.5183 - val_accuracy: 0.0413\n",
            "Epoch 189/200\n",
            "782/782 [==============================] - 190s 244ms/step - loss: 4.5160 - accuracy: 0.0412 - val_loss: 4.5181 - val_accuracy: 0.0416\n",
            "Epoch 190/200\n",
            "782/782 [==============================] - 190s 244ms/step - loss: 4.5158 - accuracy: 0.0417 - val_loss: 4.5178 - val_accuracy: 0.0412\n",
            "Epoch 191/200\n",
            "782/782 [==============================] - 190s 244ms/step - loss: 4.5155 - accuracy: 0.0411 - val_loss: 4.5175 - val_accuracy: 0.0413\n",
            "Epoch 192/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.5152 - accuracy: 0.0418 - val_loss: 4.5173 - val_accuracy: 0.0418\n",
            "Epoch 193/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.5150 - accuracy: 0.0417 - val_loss: 4.5170 - val_accuracy: 0.0421\n",
            "Epoch 194/200\n",
            "782/782 [==============================] - 191s 244ms/step - loss: 4.5147 - accuracy: 0.0418 - val_loss: 4.5168 - val_accuracy: 0.0423\n",
            "Epoch 195/200\n",
            "782/782 [==============================] - 190s 244ms/step - loss: 4.5145 - accuracy: 0.0421 - val_loss: 4.5165 - val_accuracy: 0.0425\n",
            "Epoch 196/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5142 - accuracy: 0.0423 - val_loss: 4.5163 - val_accuracy: 0.0429\n",
            "Epoch 197/200\n",
            "782/782 [==============================] - 190s 244ms/step - loss: 4.5139 - accuracy: 0.0420 - val_loss: 4.5160 - val_accuracy: 0.0429\n",
            "Epoch 198/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5137 - accuracy: 0.0422 - val_loss: 4.5158 - val_accuracy: 0.0435\n",
            "Epoch 199/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5134 - accuracy: 0.0427 - val_loss: 4.5155 - val_accuracy: 0.0431\n",
            "Epoch 200/200\n",
            "782/782 [==============================] - 190s 243ms/step - loss: 4.5132 - accuracy: 0.0424 - val_loss: 4.5153 - val_accuracy: 0.0430\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e825ec848487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SGD'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresnet_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'statistics' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7NqYWc2EE_c",
        "outputId": "132c819c-aa63-4796-83be-b7b91b432e2f"
      },
      "source": [
        "import statistics\n",
        "print(statistics.mean(resnet_history.history['accuracy']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.031498199976049364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QmgC2tAvJCj"
      },
      "source": [
        "#implemented in different file\n",
        "for layer in resnet_model.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "### LR 0.001\n",
        "tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, name=\"SGD\")\n",
        "resnet_model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "resnet_history = resnet_model.fit(x_train, y_train, batch_size=64, epochs=200, validation_data=(x_test,y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWAjI4gDJvOQ"
      },
      "source": [
        "LR 0.001 shows 0.0423, LR 0.1 shows 0.0413, LR 1 shows 0.0409, LR 0.01 shows 0.0424. In this case, LR 0.01 shows best accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJfAAOL8KxvO"
      },
      "source": [
        "1-2-(b)\n",
        "The best accraucy comes from when we do fine-tuning with learning rate 0.001. It's closely related to what we learned in the class. Since 2(a) case, we froze almost all layers, only last layer learned new information. However, in 1(a) case, we did fine-tuning to whole layers and learned new information. Then the reason of small LR 0.001 shows the best result is it allows the model to learn a more optimal. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cwKHy1EMH1F"
      },
      "source": [
        "## I also included pytorch code below (I implemented at different file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQqZ-vlfMPON"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9EiN1H2MNm1"
      },
      "source": [
        "Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCh0Tp4-MqMd"
      },
      "source": [
        "2-1. \n",
        "Weakly supervised includes data with noise. Semi-supervised learning leverages a huge amount of unlabelecd images along with a relatively smaller set of labeled data. (So, only subset of training has labels). In semi-supervised model, they train on labeled data to get an initial teacher model, and used the predictions of teacher model to get labels of unlabeled data. Thhe big difference of two models in this research is semi-supervised learning avoids the problems of long-tail distribution by selecting same number of images per label. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5wv_7lHPuvO"
      },
      "source": [
        "2-2-(a)\n",
        "Yes, according to the researchers explanation, training on large-scale hashtag data is unexpectedly robust to label noise. To do this, they collected images tagged with a specific subset of hashtags. So, they achieved 83.6% accuracy without any fine-tuning with recent ImageNet data (with finetuning 84.2%). So they got very similar result even without any fine-tuning. \n",
        "They pretrained ResNeXt-101 32x16d networks on a version of IG-1B-17k. They randomly replaced p% hashtags by other hastags obtained by sampling from the marginal distribution over hashtags. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQG2aSpWVIUi"
      },
      "source": [
        "2-2-(b)\n",
        "It reduced the impact of words that occupy the distribution. If a word is not included in a dataset, then it is less likely to be picked in training set and it might lead to poor accuracy (because it is not trained). Resampling methods make possible for including all classes' information.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWLVDzCPWxHy"
      },
      "source": [
        "2-3-(a) \n",
        "In student-teacher model, train labeled data and get a teacher model. Then,get predictions from unlabeled data using the trained teacher model and build new training data. This data is used in student model. \n",
        "The reason for it is called as distillation technique is a small(student) model is trained to match a large pre-trained (teacher) model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3PPKwwJbvLX"
      },
      "source": [
        "2-3-(b) \n",
        "Parameter K means the number of top samples from unlabeled dataset. Parameter P means number of classes assign to each image. The reason for setting P>1 is to get enough reliable data for tail classes. (because wants to take consideration of under-represented classes, or too many occuring classes) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLtTjO0SdfSa"
      },
      "source": [
        "2-3-(c) \n",
        "Run the trained model on unlabeled data and get a prediction. Then we select relevant examples for each lable to construct a new labeled dataset. Since we use top-k method for each classes, it is possible to be included in more than one class. So, the image is closely related to 2 classes, then it is one the top (included in top k). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpQf2hwbelGh"
      },
      "source": [
        "2-3-(d) Due to increase in diversity as well as we utilize samples. (a lot of data we could use). However, K further (above 8k), because of a lot of labeling noise, the accuracy will decrease. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjKJw5G9WPPl"
      },
      "source": [
        "##3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwF3RMjZnR64"
      },
      "source": [
        "3-1\n",
        "To achieve peak FLOPs, it requires customized libraries made by companies which have knolwedge about the hardware. PPP takes consideration of convolutions, pooling, dropout and fully connected layers and implement this model on a single GPU. Using this benchmark results, researchers fit a scaling constant that captures the average relative inefficiency. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvLoGe20o_38"
      },
      "source": [
        "3-2\n",
        "To calculate FLOPs there is some equations. \n",
        "In convolution layers FLOPs is 2* Number of Kernel *Kernel space*Output shape  \n",
        "In fully connected layers FLOPs is 2 * Input size * output size  \n",
        "Pooling layers FLOPs is (Height) * Depth * (Width) of an image   \n",
        "\n",
        "Conv3x3 (64) = 2 * 64 * 3 * 3 * 224* 224 *3 =173408256      \n",
        "Conv3x3 (64) = 2 * 64 * 3 * 3 * 224 * 224 * 64 =3699376128    \n",
        "MaxPool = (224/2) * (224/2) * 256 = 3211264    \n",
        "Conv3x3 (128) = 2*128 * 3 * 3 * (112)*(112)*64 = 1849688064  \n",
        "Conv3x3 (128) = 2 * 128 * 3 * 3 * (112)*(112)*128 =  3699376128  \n",
        "MaxPool = (112) * (112) * 128 = 1605632  \n",
        "Conv3x3 (256) = 2*256 * 3 * 3 * (56) * (56)*128 = 1849688064  \n",
        "Conv3x3 (256)= 2 * 256 * 3 * 3 * (56) * (56)*256 = 3699376128  \n",
        "Conv3x3 (256)= 2 * 256 * 3 * 3 * (56) * (56)*256=3699376128    \n",
        "Conv3x3 (256)=  2 * 256 * 3 * 3 * (56) * (56) *256=3699376128    \n",
        "MaxPool = (56) * (56) * 256 = 802816     \n",
        "Conv3x3 (512) = 2*256 * 3 * 3 * (28) * (28)*512 = 1849688064     \n",
        "Conv3x3 (512)= 2 * 512 * 3 * 3 * (28) * (28)*512=3699376128     \n",
        "Conv3x3 (512)= 2 * 512 * 3 * 3 * (28) * (28)*512=3699376128     \n",
        "Conv3x3 (512)= 2 * 512 * 3 * 3 * (28) * (28)*512 = 3699376128      \n",
        "MaxPool = (28) * (28) * 512 = 401408     \n",
        "Conv3x3 (512)= 2 * 512 * 3 * 3 * (14) * (14)*512= 924844032     \n",
        "Conv3x3 (512)= 2 * 512 * 3 * 3 * (14) * (14)*512=924844032      \n",
        "Conv3x3 (512)= 2 * 512 * 3 * 3 * (14) * (14)*512=924844032     \n",
        "Conv3x3 (512)= 2 * 512 * 3 * 3 * (14) * (14)*512=924844032     \n",
        "MaxPool  = (14) * (14) * 512 =100352    \n",
        "Fully Connected (4096) = 2 * 25088 * 4096 =205520896    \n",
        "Fully Connected (4096)= 2 * 4096* 4096 = 33554432  \n",
        "Fully Connected (1000)= 2 * 4096 * 1000=8192000\n",
        "\n",
        "FLOPS (x 10^-6): 39270.24640000 FLOPs \n",
        "FLOPs in Convolution layers = 392449075200\n",
        "392449075200/3927026460000*100 = 99.354%\n",
        "Total MACCs: 19632062464.00000000 (1MAC = 2FLOPs)\n",
        "Most of FLOPs (99%) are related to convolution layers.\n",
        "\n",
        "https://www.thinkautonomous.ai/blog/?p=deep-learning-optimization#inference\n",
        "\n",
        "https://iq.opengenus.org/floating-point-operations-per-second-flops-of-machine-learning-models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMunrEfUhwNS"
      },
      "source": [
        "3-3\n",
        "Summation of layerwise timing doesn't match the timing of the full foward pass on GPUs. CUDA supports asynchronous programming. Before time measurement, API has to be called to make sure all cores finished their tasks. Thus, it is overhead of measuring time on GPUs. Summation of layerwise timing on GPUs is longer than a full forward pass.  \n",
        "To mitigate this situation, they benchmark a matrix multiplication. They kept GPUs iteratively running the matrix multiplication in a way that GPU cores can continuously perform multiply add operations without synchronization before recording the end time. So, if the iteration number is large enough, the overhead can be ignored. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-nSMx4NkUdw"
      },
      "source": [
        "3-4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk8En7uMFBdf"
      },
      "source": [
        "K80's peak double precision floating point performance is 1.87. \n",
        "The inference time will be FLOPs/FLOPs (1GFLOPS = 1000000000) \n",
        "since 1tflops = 1000gflops \n",
        "\n",
        "VGG = (15503*10^6)/(1.87*1000*10^9) = 0.00829037433s   \n",
        "GoogleNet = (1606*10^6)/(1.87*1000*10^9) = 0.00085882352s    \n",
        "ResNet = (3922*10^6)/(1.87*1000*10^9) = 0.0020973262s\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvVisabY8Nj_"
      },
      "source": [
        "##4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiD2sjMqMU5U"
      },
      "source": [
        "What I did was k80 (18, 44, 56 depth model), there is different implementation files. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1oSjDGdLIj8"
      },
      "source": [
        " 4-1 (not completed)\n",
        "Team member: Sweta Bharti, Harshita Kukreja, Dan Zhao, Graham Jones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeFgsfrVoQC-"
      },
      "source": [
        "4-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skl6sLPT8NUQ"
      },
      "source": [
        "import six\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "\n",
        "\n",
        "def _bn_relu(x, bn_name=None, relu_name=None):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS, name=bn_name)(x)\n",
        "    return Activation(\"relu\", name=relu_name)(norm)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu residual unit activation function.\n",
        "       This is the original ResNet v1 scheme in https://arxiv.org/abs/1512.03385\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    dilation_rate = conv_params.setdefault(\"dilation_rate\", (1, 1))\n",
        "    conv_name = conv_params.setdefault(\"conv_name\", None)\n",
        "    bn_name = conv_params.setdefault(\"bn_name\", None)\n",
        "    relu_name = conv_params.setdefault(\"relu_name\", None)\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(x):\n",
        "        x = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                   strides=strides, padding=padding,\n",
        "                   dilation_rate=dilation_rate,\n",
        "                   kernel_initializer=kernel_initializer,\n",
        "                   kernel_regularizer=kernel_regularizer,\n",
        "                   name=conv_name)(x)\n",
        "        return _bn_relu(x, bn_name=bn_name, relu_name=relu_name)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv residual unit with full pre-activation\n",
        "    function. This is the ResNet v2 scheme proposed in\n",
        "    http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    dilation_rate = conv_params.setdefault(\"dilation_rate\", (1, 1))\n",
        "    conv_name = conv_params.setdefault(\"conv_name\", None)\n",
        "    bn_name = conv_params.setdefault(\"bn_name\", None)\n",
        "    relu_name = conv_params.setdefault(\"relu_name\", None)\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(x):\n",
        "        activation = _bn_relu(x, bn_name=bn_name, relu_name=relu_name)\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      dilation_rate=dilation_rate,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer,\n",
        "                      name=conv_name)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut(input_feature, residual, conv_name_base=None, bn_name_base=None):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input_feature)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input_feature\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        print('reshaping via a convolution...')\n",
        "        if conv_name_base is not None:\n",
        "            conv_name_base = conv_name_base + '1'\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001),\n",
        "                          name=conv_name_base)(input_feature)\n",
        "        if bn_name_base is not None:\n",
        "            bn_name_base = bn_name_base + '1'\n",
        "        shortcut = BatchNormalization(axis=CHANNEL_AXIS,\n",
        "                                      name=bn_name_base)(shortcut)\n",
        "\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, blocks, stage,\n",
        "                    transition_strides=None, transition_dilation_rates=None,\n",
        "                    dilation_rates=None, is_first_layer=False, dropout=None,\n",
        "                    residual_unit=_bn_relu_conv):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "       stage: integer, current stage label, used for generating layer names\n",
        "       blocks: number of blocks 'a','b'..., current block label, used for generating\n",
        "            layer names\n",
        "       transition_strides: a list of tuples for the strides of each transition\n",
        "       transition_dilation_rates: a list of tuples for the dilation rate of each\n",
        "            transition\n",
        "    \"\"\"\n",
        "    if transition_dilation_rates is None:\n",
        "        transition_dilation_rates = [(1, 1)] * blocks\n",
        "    if transition_strides is None:\n",
        "        transition_strides = [(1, 1)] * blocks\n",
        "    if dilation_rates is None:\n",
        "        dilation_rates = [1] * blocks\n",
        "\n",
        "    def f(x):\n",
        "        for i in range(blocks):\n",
        "            is_first_block = is_first_layer and i == 0\n",
        "            x = block_function(filters=filters, stage=stage, block=i,\n",
        "                               transition_strides=transition_strides[i],\n",
        "                               dilation_rate=dilation_rates[i],\n",
        "                               is_first_block_of_first_layer=is_first_block,\n",
        "                               dropout=dropout,\n",
        "                               residual_unit=residual_unit)(x)\n",
        "        return x\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _block_name_base(stage, block):\n",
        "    \"\"\"Get the convolution name base and batch normalization name base defined by\n",
        "    stage and block.\n",
        "    If there are less than 26 blocks they will be labeled 'a', 'b', 'c' to match the\n",
        "    paper and keras and beyond 26 blocks they will simply be numbered.\n",
        "    \"\"\"\n",
        "    if block < 27:\n",
        "        block = '%c' % (block + 97)  # 97 is the ascii number for lowercase 'a'\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    return conv_name_base, bn_name_base\n",
        "\n",
        "\n",
        "def basic_block(filters, stage, block, transition_strides=(1, 1),\n",
        "                dilation_rate=(1, 1), is_first_block_of_first_layer=False, dropout=None,\n",
        "                residual_unit=_bn_relu_conv):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input_features):\n",
        "        conv_name_base, bn_name_base = _block_name_base(stage, block)\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            x = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                       strides=transition_strides,\n",
        "                       dilation_rate=dilation_rate,\n",
        "                       padding=\"same\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=l2(1e-4),\n",
        "                       name=conv_name_base + '2a')(input_features)\n",
        "        else:\n",
        "            x = residual_unit(filters=filters, kernel_size=(3, 3),\n",
        "                              strides=transition_strides,\n",
        "                              dilation_rate=dilation_rate,\n",
        "                              conv_name_base=conv_name_base + '2a',\n",
        "                              bn_name_base=bn_name_base + '2a')(input_features)\n",
        "\n",
        "        if dropout is not None:\n",
        "            x = Dropout(dropout)(x)\n",
        "\n",
        "        x = residual_unit(filters=filters, kernel_size=(3, 3),\n",
        "                          conv_name_base=conv_name_base + '2b',\n",
        "                          bn_name_base=bn_name_base + '2b')(x)\n",
        "\n",
        "        return _shortcut(input_features, x)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, stage, block, transition_strides=(1, 1),\n",
        "               dilation_rate=(1, 1), is_first_block_of_first_layer=False, dropout=None,\n",
        "               residual_unit=_bn_relu_conv):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input_feature):\n",
        "        conv_name_base, bn_name_base = _block_name_base(stage, block)\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            x = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                       strides=transition_strides,\n",
        "                       dilation_rate=dilation_rate,\n",
        "                       padding=\"same\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=l2(1e-4),\n",
        "                       name=conv_name_base + '2a')(input_feature)\n",
        "        else:\n",
        "            x = residual_unit(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=transition_strides,\n",
        "                              dilation_rate=dilation_rate,\n",
        "                              conv_name_base=conv_name_base + '2a',\n",
        "                              bn_name_base=bn_name_base + '2a')(input_feature)\n",
        "\n",
        "        if dropout is not None:\n",
        "            x = Dropout(dropout)(x)\n",
        "\n",
        "        x = residual_unit(filters=filters, kernel_size=(3, 3),\n",
        "                          conv_name_base=conv_name_base + '2b',\n",
        "                          bn_name_base=bn_name_base + '2b')(x)\n",
        "\n",
        "        if dropout is not None:\n",
        "            x = Dropout(dropout)(x)\n",
        "\n",
        "        x = residual_unit(filters=filters * 4, kernel_size=(1, 1),\n",
        "                          conv_name_base=conv_name_base + '2c',\n",
        "                          bn_name_base=bn_name_base + '2c')(x)\n",
        "\n",
        "        return _shortcut(input_feature, x)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_data_format() == 'channels_last':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "\n",
        "\n",
        "def _string_to_function(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "def ResNet(input_shape=None, classes=10, block='bottleneck', residual_unit='v2',\n",
        "           repetitions=None, initial_filters=64, activation='softmax', include_top=True,\n",
        "           input_tensor=None, dropout=None, transition_dilation_rate=(1, 1),\n",
        "           initial_strides=(2, 2), initial_kernel_size=(7, 7), initial_pooling='max',\n",
        "           final_pooling=None, top='classification'):\n",
        "    \"\"\"Builds a custom ResNet like architecture. Defaults to ResNet50 v2.\n",
        "    Args:\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)` (with `channels_last` dim ordering)\n",
        "            or `(3, 224, 224)` (with `channels_first` dim ordering).\n",
        "            It should have exactly 3 dimensions,\n",
        "            and width and height should be no smaller than 8.\n",
        "            E.g. `(224, 224, 3)` would be one valid value.\n",
        "        classes: The number of outputs at final softmax layer\n",
        "        block: The block function to use. This is either `'basic'` or `'bottleneck'`.\n",
        "            The original paper used `basic` for layers < 50.\n",
        "        repetitions: Number of repetitions of various block units.\n",
        "            At each block unit, the number of filters are doubled and the input size\n",
        "            is halved. Default of None implies the ResNet50v2 values of [3, 4, 6, 3].\n",
        "        residual_unit: the basic residual unit, 'v1' for conv bn relu, 'v2' for bn relu\n",
        "            conv. See [Identity Mappings in\n",
        "            Deep Residual Networks](https://arxiv.org/abs/1603.05027)\n",
        "            for details.\n",
        "        dropout: None for no dropout, otherwise rate of dropout from 0 to 1.\n",
        "            Based on [Wide Residual Networks.(https://arxiv.org/pdf/1605.07146) paper.\n",
        "        transition_dilation_rate: Dilation rate for transition layers. For semantic\n",
        "            segmentation of images use a dilation rate of (2, 2).\n",
        "        initial_strides: Stride of the very first residual unit and MaxPooling2D call,\n",
        "            with default (2, 2), set to (1, 1) for small images like cifar.\n",
        "        initial_kernel_size: kernel size of the very first convolution, (7, 7) for\n",
        "            imagenet and (3, 3) for small image datasets like tiny imagenet and cifar.\n",
        "            See [ResNeXt](https://arxiv.org/abs/1611.05431) paper for details.\n",
        "        initial_pooling: Determine if there will be an initial pooling layer,\n",
        "            'max' for imagenet and None for small image datasets.\n",
        "            See [ResNeXt](https://arxiv.org/abs/1611.05431) paper for details.\n",
        "        final_pooling: Optional pooling mode for feature extraction at the final\n",
        "            model layer when `include_top` is `False`.\n",
        "            - `None` means that the output of the model\n",
        "                will be the 4D tensor output of the\n",
        "                last convolutional layer.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a\n",
        "                2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        top: Defines final layers to evaluate based on a specific problem type. Options\n",
        "            are 'classification' for ImageNet style problems, 'segmentation' for\n",
        "            problems like the Pascal VOC dataset, and None to exclude these layers\n",
        "            entirely.\n",
        "    Returns:\n",
        "        The keras `Model`.\n",
        "    \"\"\"\n",
        "    if activation not in ['softmax', 'sigmoid', None]:\n",
        "        raise ValueError('activation must be one of \"softmax\", \"sigmoid\", or None')\n",
        "    if activation == 'sigmoid' and classes != 1:\n",
        "        raise ValueError('sigmoid activation can only be used when classes = 1')\n",
        "    if repetitions is None:\n",
        "        repetitions = [3, 4, 6, 3]\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=32,\n",
        "                                      min_size=8,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top)\n",
        "    _handle_dim_ordering()\n",
        "    if len(input_shape) != 3:\n",
        "        raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "    if block == 'basic':\n",
        "        block_fn = basic_block\n",
        "    elif block == 'bottleneck':\n",
        "        block_fn = bottleneck\n",
        "    elif isinstance(block, six.string_types):\n",
        "        block_fn = _string_to_function(block)\n",
        "    else:\n",
        "        block_fn = block\n",
        "\n",
        "    if residual_unit == 'v2':\n",
        "        residual_unit = _bn_relu_conv\n",
        "    elif residual_unit == 'v1':\n",
        "        residual_unit = _conv_bn_relu\n",
        "    elif isinstance(residual_unit, six.string_types):\n",
        "        residual_unit = _string_to_function(residual_unit)\n",
        "    else:\n",
        "        residual_unit = residual_unit\n",
        "\n",
        "    # Permute dimension order if necessary\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=32,\n",
        "                                      min_size=8,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    img_input = Input(shape=input_shape, tensor=input_tensor)\n",
        "    x = _conv_bn_relu(filters=initial_filters, kernel_size=initial_kernel_size,\n",
        "                      strides=initial_strides)(img_input)\n",
        "    if initial_pooling == 'max':\n",
        "        x = MaxPooling2D(pool_size=(3, 3), strides=initial_strides, padding=\"same\")(x)\n",
        "\n",
        "    block = x\n",
        "    filters = initial_filters\n",
        "    for i, r in enumerate(repetitions):\n",
        "        transition_dilation_rates = [transition_dilation_rate] * r\n",
        "        transition_strides = [(1, 1)] * r\n",
        "        if transition_dilation_rate == (1, 1):\n",
        "            transition_strides[0] = (2, 2)\n",
        "        block = _residual_block(block_fn, filters=filters,\n",
        "                                stage=i, blocks=r,\n",
        "                                is_first_layer=(i == 0),\n",
        "                                dropout=dropout,\n",
        "                                transition_dilation_rates=transition_dilation_rates,\n",
        "                                transition_strides=transition_strides,\n",
        "                                residual_unit=residual_unit)(block)\n",
        "        filters *= 2\n",
        "\n",
        "    # Last activation\n",
        "    x = _bn_relu(block)\n",
        "\n",
        "    # Classifier block\n",
        "    if include_top and top is 'classification':\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(units=classes, activation=activation,\n",
        "                  kernel_initializer=\"he_normal\")(x)\n",
        "    elif include_top and top is 'segmentation':\n",
        "        x = Conv2D(classes, (1, 1), activation='linear', padding='same')(x)\n",
        "\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            channel, row, col = input_shape\n",
        "        else:\n",
        "            row, col, channel = input_shape\n",
        "\n",
        "        x = Reshape((row * col, classes))(x)\n",
        "        x = Activation(activation)(x)\n",
        "        x = Reshape((row, col, classes))(x)\n",
        "    elif final_pooling == 'avg':\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "    elif final_pooling == 'max':\n",
        "        x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "    model = Model(inputs=img_input, outputs=x)\n",
        "    return model\n",
        "\n",
        "\n",
        "def ResNet18(input_shape, classes):\n",
        "    \"\"\"ResNet with 18 layers and v2 residual units\n",
        "    \"\"\"\n",
        "    return ResNet(input_shape, classes, basic_block, repetitions=[2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34(input_shape, classes):\n",
        "    \"\"\"ResNet with 34 layers and v2 residual units\n",
        "    \"\"\"\n",
        "    return ResNet(input_shape, classes, basic_block, repetitions=[3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50(input_shape, classes):\n",
        "    \"\"\"ResNet with 50 layers and v2 residual units\n",
        "    \"\"\"\n",
        "    return ResNet(input_shape, classes, bottleneck, repetitions=[3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101(input_shape, classes):\n",
        "    \"\"\"ResNet with 101 layers and v2 residual units\n",
        "    \"\"\"\n",
        "    return ResNet(input_shape, classes, bottleneck, repetitions=[3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152(input_shape, classes):\n",
        "    \"\"\"ResNet with 152 layers and v2 residual units\n",
        "    \"\"\"\n",
        "    return ResNet(input_shape, classes, bottleneck, repetitions=[3, 8, 36, 3])\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.history = {'loss':[],'val_loss':[]}\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "#https://stackoverflow.com/questions/42392441/how-to-record-val-loss-and-loss-per-batch-in-keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EED-6k_c4d-D"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzSswOSloYxh"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train  /= 255.0\n",
        "x_test /= 255.0\n",
        "y_train=np_utils.to_categorical(y_train)\n",
        "y_test=np_utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6ZgsMlZohf0"
      },
      "source": [
        "model = ResNet50(weights=None, classes=100, input_shape=(32, 32, 3))\n",
        "tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, name=\"SGD\")\n",
        "resnet_model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "lossbatch = LossHistory()\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=350, callbacks=[lossbatch],verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNEU4f8swvD2"
      },
      "source": [
        "import numpy as np\n",
        "def objective(k, beta0, beta1, beta2):\n",
        "\treturn 1/(beta0*k+beta1)+beta2\n",
        "\n",
        "loss_data = df['loss'] \n",
        "acc_data = df['accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJEl8FR0w1lP"
      },
      "source": [
        "idx = np.array(list(range(1, len(loss_data)+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_Tz079Rql9d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(idx, loss_data)\n",
        "plt.plot(idx, acc_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3KuhEPzvcYF"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "popt, pcurv = curve_fit(objective, idx, loss_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFSMhOFdLmbY"
      },
      "source": [
        "print(popt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5d76eLK7eYu"
      },
      "source": [
        "K80-resnet44"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5J5KUPB7ZmV"
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# Training parameters\n",
        "BATCH_SIZE = 128  # orig paper trained all networks with batch_size=128\n",
        "EPOCHS = 350 # 200\n",
        "USE_AUGMENTATION = True\n",
        "NUM_CLASSES = np.unique(y_train).shape[0] # 10\n",
        "COLORS = x_train.shape[3]\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "SUBTRACT_PIXEL_MEAN = True\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), \n",
        "# Improved ResNet: version = 2 \n",
        "# (ResNet v2)\n",
        "VERSION = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if VERSION == 1:\n",
        "    DEPTH = COLORS * 6 + 2\n",
        "elif version == 2:\n",
        "    DEPTH = COLORS * 9 + 2\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature \n",
        "    map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of \n",
        "    filters is\n",
        "    doubled. Within each stage, the layers have the same number \n",
        "    filters and the same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:  \n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:  \n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = tensorflow.keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if SUBTRACT_PIXEL_MEAN:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.history = {'loss':[],'accuracy':[]}\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "model = resnet_v1(depth = 44, num_classes=10, input_shape=(32, 32, 3))\n",
        "tf.keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False, name=\"SGD\")\n",
        "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "lossbatch = LossHistory()\n",
        "history1 = model.fit(x_train, y_train, batch_size=128, epochs=350, callbacks=[lossbatch],verbose=0)\n",
        "history1\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import pandas as pd\n",
        "import io\n",
        "df = pd.read_csv(io.StringIO(uploaded['resnet18.txt'].decode('utf-8')), sep=\"\\t\")\n",
        "import numpy as np\n",
        "def objective(k, beta0, beta1, beta2):\n",
        "\treturn 1/(beta0*k+beta1)+beta2\n",
        "\n",
        "loss_data = df['loss'] \n",
        "acc_data = df['accuracy']\n",
        "idx = np.array(list(range(1, len(loss_data)+1)))\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(idx, loss_data)\n",
        "plt.plot(idx, acc_data)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "popt, pcurv = curve_fit(objective, idx, loss_data)\n",
        "print(popt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dbc_vsC6q_0"
      },
      "source": [
        "K80-resnet56"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adeVl5tE7EMS"
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# Training parameters\n",
        "BATCH_SIZE = 128  # orig paper trained all networks with batch_size=128\n",
        "EPOCHS = 350 # 200\n",
        "USE_AUGMENTATION = True\n",
        "NUM_CLASSES = np.unique(y_train).shape[0] # 10\n",
        "COLORS = x_train.shape[3]\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "SUBTRACT_PIXEL_MEAN = True\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), \n",
        "# Improved ResNet: version = 2 \n",
        "# (ResNet v2)\n",
        "VERSION = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if VERSION == 1:\n",
        "    DEPTH = COLORS * 6 + 2\n",
        "elif version == 2:\n",
        "    DEPTH = COLORS * 9 + 2\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature \n",
        "    map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of \n",
        "    filters is\n",
        "    doubled. Within each stage, the layers have the same number \n",
        "    filters and the same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:  \n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            # first layer but not first stack\n",
        "            if stack > 0 and res_block == 0:  \n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = tensorflow.keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if SUBTRACT_PIXEL_MEAN:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.history = {'loss':[],'accuracy':[]}\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.history['loss'].append(logs.get('loss'))\n",
        "        self.history['accuracy'].append(logs.get('accuracy'))\n",
        "model = resnet_v1(depth = 56, num_classes=10, input_shape=(32, 32, 3))\n",
        "tf.keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False, name=\"SGD\")\n",
        "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "lossbatch = LossHistory()\n",
        "history1 = model.fit(x_train, y_train, batch_size=128, epochs=350, callbacks=[lossbatch],verbose=0)\n",
        "history1\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import pandas as pd\n",
        "import io\n",
        "df = pd.read_csv(io.StringIO(uploaded['resnet18.txt'].decode('utf-8')), sep=\"\\t\")\n",
        "import numpy as np\n",
        "def objective(k, beta0, beta1, beta2):\n",
        "\treturn 1/(beta0*k+beta1)+beta2\n",
        "\n",
        "loss_data = df['loss'] \n",
        "acc_data = df['accuracy']\n",
        "idx = np.array(list(range(1, len(loss_data)+1)))\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(idx, loss_data)\n",
        "plt.plot(idx, acc_data)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "popt, pcurv = curve_fit(objective, idx, loss_data)\n",
        "print(popt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVQrGuAlq7U-"
      },
      "source": [
        "4-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO6nhnse7sPN"
      },
      "source": [
        "## after collecting 4-1 data \n",
        "depth = [18,20,32,44,56]\n",
        "k80 =[]\n",
        "p100=[]\n",
        "v100=[]\n",
        "from sklearn import linear_model\n",
        "for dat in k80:\n",
        "  model = linear_model.LinearRegression()\n",
        "  model.fit(depth,dat)\n",
        "  print(model.coef_)\n",
        "\n",
        "  plt.scatter(depth,dat)\n",
        "  input=np.arange(1,60)\n",
        "  plt.plot(input,model.coef_*input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcgtIVe-810e"
      },
      "source": [
        "for dat in p100:\n",
        "  model = linear_model.LinearRegression()\n",
        "  model.fit(depth,dat)\n",
        "  print(model.coef_)\n",
        "  plt.scatter(depth,dat)\n",
        "  input=np.arange(1,60)\n",
        "  plt.plot(input,model.coef_*input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQu9nPTH85F1"
      },
      "source": [
        "for dat in v100:\n",
        "  model = linear_model.LinearRegression()\n",
        "  model.fit(depth,dat)\n",
        "  print(model.coef_)\n",
        "  plt.scatter(depth,dat)\n",
        "  input=np.arange(1,60)\n",
        "  plt.plot(input,model.coef_*input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlQ9jpE7m9js"
      },
      "source": [
        "model = resnet_v1(depth = 50)\n",
        "tf.keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False, name=\"SGD\")\n",
        "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "lossbatch = LossHistory()\n",
        "history1 = model.fit(x_train, y_train, batch_size=128, epochs=350, callbacks=[lossbatch],verbose=0)\n",
        "history1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndGx4DDCMwXk"
      },
      "source": [
        "def fit(self):\n",
        "    print (\"Fitting a model with \", len(self.training_data), \" points\")\n",
        "    labels = np.array([row[2] for row in self.training_data])\n",
        "    data_points = np.array([self._get_features(row) for row in self.training_data])\n",
        "    self.model = nnls(data_points, labels)\n",
        "\n",
        "    training_accuracy = []\n",
        "    for p in self.training_data:\n",
        "      predicted = self.predict(p[0], p[1])\n",
        "      training_accuracy.append(predicted / p[2])\n",
        "\n",
        "    print (\"Average training accuracy %f%%\" % ((np.mean(trainingg_errors) - 1.0)*100.0 ))\n",
        "    return self.model[0] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eWb-0guAw1Y"
      },
      "source": [
        "4-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu4IMRHRAt_Y"
      },
      "source": [
        "worker = []\n",
        "def peng_equation(ps, worker,batch_size):\n",
        "  res = 1/(1.02*batch_size/worker+2.78+4.92*worker/ps+0*worker+0.02*ps)\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_zixDL3DPHL"
      },
      "source": [
        "#parameter server for 2\n",
        "val = []\n",
        "for i in worker:\n",
        "  value = peng_equation(2, i, batch_size)\n",
        "  val.append()\n",
        "plt.plot(worker,val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z013Qv8NDn8H"
      },
      "source": [
        "#parameter server for 4\n",
        "val = []\n",
        "for i in worker:\n",
        "  value = peng_equation(4, i, batch_size)\n",
        "  val.append()\n",
        "\n",
        "plt.plot(worker,val)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}